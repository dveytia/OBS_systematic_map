---
title: "12-MS-figures_v1"
author: "Devi Veytia"
date: "2023-09-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 0. Set up


```{r load libraries}
library(dplyr)
library(dbplyr)
library(R.utils)
library(RSQLite)
library(ggplot2)

```

```{r database filepath}
all_db_fp <- here::here("data","raw-data","sql-databases", "all_tables_v1.sqlite")

```

```{r colourpalette}
branchPal <- c("Mitigation" = "#35a7d9","Nature" = "forestgreen", "Societal"="#7670a8")

```




# 1. Summarise the corpus


```{r PRISMA diagram}

## SQLITE CALCULATIONS

# connect to db
all_db <- RSQLite::dbConnect(RSQLite::SQLite(),all_db_fp, create=FALSE) 

# Get a table with all the references and calculate:
# number retreived from each source
# number of unseen articles
allrefs <- tbl(all_db,"allrefs_join") 
databaseNum <- allrefs%>%group_by(source_database)%>% summarise(n=n()) %>% as.data.frame() 
naAbstracts <- allrefs%>%filter(is.na(abstract))%>% summarise(n=n()) %>% as.data.frame()

# Get a table of all the de-duplicated references 
dedups <- tbl(all_db, "uniquerefs") 
nUnique <- dedups %>%
  filter(!is.na(abstract)) %>%
  summarise(n=n())%>%
  as.data.frame()

# Get a table of all those predicted to be relevant
predRel <- tbl(all_db, "predRel2")
nInclude <- predRel %>% 
  summarise(
    lower = sum(0.5 <= relevance_lower),
    mean = sum(0.5 <= relevance_mean),
    upper = sum(0.5 <= relevance_upper)) %>%
  as.data.frame()

# Disconnect the database
dbDisconnect(all_db)



## PLOT THE PRISMA DIAGRAM


PRISMAFlow <- c(
  paste("START_PHASE:", 
        format(databaseNum$n[databaseNum$source_database == "Web Of Science"], format = "d", big.mark=","),
        "articles from WOS"),
  paste("START_PHASE:", format(databaseNum$n[databaseNum$source_database == "Scopus"], 
                               format = "d", big.mark=","),
        "articles from Scopus"),
  paste(format(sum(databaseNum$n), format = "d", big.mark=","),"articles in total"),
  paste("EXCLUDE_PHASE:", format(naAbstracts, format = "d", big.mark=","),"abstracts removed as NA"),
  paste(format(sum(databaseNum$n)-naAbstracts, format = "d", big.mark=","),"eligible articles"),
  paste("EXCLUDE_PHASE:",
        format(sum(databaseNum$n)-naAbstracts-nUnique, format = "d", big.mark=","),"duplicates removed"),
  paste(format(nUnique, format = "d", big.mark=","),"unique articles"),
  paste("EXCLUDE_PHASE:", format(nUnique-nInclude[3], format = "d", big.mark=","),"articles excluded"),
  paste(format(nInclude[3], format = "d", big.mark=","),"articles predicted relevant (upper)")
)

w <- 12
h <- w*0.7

pdf(here::here("figures/supplementary/prisma-diagram.pdf"), width = w, height = h)
PRISMAFlowChart <- metagear::plot_PRISMA(PRISMAFlow, 
                                         design = c(E = "lightcoral", flatArrow = TRUE),
                                         excludeDistance = 0.8, colWidth = 50)
dev.off()

```


# Broad trends and WOS metadata

```{r Annual trend in number of documents}

## SQLITE CALCULATIONS
# connect to db and load tables
all_db <- RSQLite::dbConnect(RSQLite::SQLite(),all_db_fp, create=FALSE)
dedups <- tbl(all_db,"uniquerefs")
predRel <- tbl(all_db, "predRel2") 
predBranch <- tbl(all_db, "predBranch")

# Calculate the number of relevant predictions for each year
df <- predRel %>%
  left_join(dedups, by="analysis_id") %>%
  left_join(predBranch, by = "analysis_id") %>%
  filter(!is.na(year)) %>%
  group_by(year) %>%
  summarise(n_lower = sum(0.5 <= relevance_lower),
            n_total = sum(0.5 <= relevance_mean),
            n_upper = sum(0.5 <= relevance_upper),
            n_mitigation = sum(0.5 <= Mitigation_mean & 0.5 <= relevance_mean),
            n_nature = sum(0.5 <= Nature_mean & 0.5 <= relevance_mean),
            n_societal = sum(0.5 <= Societal_mean & 0.5 <= relevance_mean)) %>%
  collect()

# Disconnect the database
dbDisconnect(all_db)


## Data formatting
df$year <- as.Date(paste0("01-01-", df$year), format = "%d-%m-%Y")
df <- df %>% filter(year < as.Date("01-01-2023", format = "%d-%m-%Y"))

df_melt <- reshape2::melt(df, measure.vars = c("n_total","n_mitigation","n_nature","n_societal"),
                     value.name = "mean_prediction", variable.name = "variable") %>%
  mutate(variable = factor(variable, levels = c("n_total","n_mitigation","n_nature","n_societal"),
                           labels = c("All articles","Mitigation","Natural resilience","Societal\nadaptation")))
  
# add log scale
df_log <- df %>%
  mutate(n_lower = log(n_lower), n_upper = log(n_upper), scale = "log")
df_log <- rbind(
  df %>% mutate(scale = "normal"),
  df_log
)
df_log$scale <- factor(df_log$scale,
                       levels = c("normal","log"),
                       labels = c("un-transformed","log-transformed"))

df_melt_log <- df_melt %>%
  mutate(mean_prediction = log(mean_prediction), scale = "log")
df_melt_log <- rbind(
  df_melt %>% mutate(scale = "normal"),
  df_melt_log
)
df_melt_log$scale <- factor(df_melt_log$scale, 
                            levels = c("normal","log"),
                            labels = c("un-transformed","log-transformed"))

# Model fit
mod <- lm(log(n_total)~year, data = df, subset = n_total > 0)
summary(mod)
pred_df <- data.frame(year = seq(min(df$year), max(df$year), by=1))
pred_y <- predict(mod, pred_df, interval = "confidence", type="response")
pred_df <- rbind(
  cbind(pred_df, as.data.frame(pred_y), data.frame(scale = rep("log-transformed", nrow(pred_df)))),
  cbind(pred_df, as.data.frame(exp(pred_y)), data.frame(scale = rep("un-transformed", nrow(pred_df))))
)
pred_df$scale <- factor(pred_df$scale, levels = c("un-transformed","log-transformed"))



formula_text <- data.frame(
  label = paste0("y == ", 
                 format(coef(mod)[1], scientific=TRUE, digits = 2), "*(",
                 format(coef(mod)[2], scientific=TRUE, digits = 2),"^x)"),
  year=as.Date("1932-01-01"),
  y=max(df$n_total),
  scale = factor("un-transformed", levels = c("un-transformed","log-transformed"))
)

## Plot
annualTrend_ggp <- ggplot()+
  facet_grid(scale ~., scales = "free_y")+
  geom_ribbon(data=df_log, aes(x=year, ymin = n_lower, ymax = n_upper), fill = "lightgrey")+
  geom_line(data = df_melt_log, aes(x=year, y=mean_prediction, col = variable), linewidth = 1)+
  geom_line(data = pred_df, aes(x=year, y=fit), col="red", linetype = "dashed", linewidth = 1)+
  geom_text(data=formula_text, aes(x=year, y=y, 
                                   label = label),parse=TRUE, color = "red")+
  geom_text(data=formula_text, aes(x=year, y=y-1000, 
                                   label = paste("R^2 == ",
                                                 format(summary(mod)$adj.r.squared, digits = 2))),
            color = "red", parse=TRUE)+
  scale_color_manual(values = c("black",as.vector(branchPal)), 
                     name = "Mean predicted\nrelevance")+
  labs(x="Year", y="Number of articles predicted relevant", 
       caption = "all terms are significant p << 0.05")+
  scale_x_date()+
  theme_classic()+
  theme(legend.position = "bottom")

annualTrend_ggp

ggsave(here::here("figures/main/annual-trends.pdf"),plot=annualTrend_ggp,
       width = 7, height=4.5, units="in")

```


```{r Annual trend by research area}
## SQLITE CALCULATIONS
# connect to db and load tables
all_db <- RSQLite::dbConnect(RSQLite::SQLite(),all_db_fp, create=FALSE)
dedups <- tbl(all_db,"uniquerefs") %>% filter(!is.na(abstract))
predRel <- tbl(all_db, "predRel2") 
predBranch <- tbl(all_db, "predBranch")

# "research_areas", web_of_science_categories",
# Don't do "organization or" "funding" or "affiliation"  yet, wait to compare to geoparsing results

# Calculate the number of relevant predictions for each year
n_relevant <- predRel %>%
  left_join(dedups, by="analysis_id") %>%
  left_join(predBranch, by = "analysis_id") %>%
  filter(!is.na(year)) %>%
  group_by(year) %>%
  summarise(n_lower = sum(0.5 <= relevance_lower),
            n_total = sum(0.5 <= relevance_mean),
            n_upper = sum(0.5 <= relevance_upper),
            n_mitigation = sum(0.5 <= Mitigation_mean & 0.5 <= relevance_mean),
            n_nature = sum(0.5 <= Nature_mean & 0.5 <= relevance_mean),
            n_societal = sum(0.5 <= Societal_mean & 0.5 <= relevance_mean)) %>%
  collect()

research_area_df <- predRel %>%
  filter(0.5 <= relevance_upper) %>%
  left_join(dedups, by="analysis_id") %>%
  filter(!is.na(research_areas)) %>%
  select(analysis_id, duplicate_id, research_areas, web_of_science_categories, year)%>%
  filter(!is.na(year)) %>%
  mutate(research_areas = eval(parse(text=gsub("\\", "", deparse(research_areas), fixed=TRUE))),
         first_research_area = gsub("\\;.*","", research_areas)) %>%
  collect()

# Disconnect the database
dbDisconnect(all_db)




## Data Formatting & Calculations

## For number of relevant articles
# year as date
n_relevant$year <- as.Date(paste0("01-01-", n_relevant$year), format = "%d-%m-%Y")
n_relevant <- n_relevant %>% filter(year < as.Date("01-01-2023", format = "%d-%m-%Y"))

# Melt by ORO branch
n_relevant_melt <- reshape2::melt(n_relevant, measure.vars = c("n_total","n_mitigation","n_nature","n_societal"),
                     value.name = "mean_prediction", variable.name = "variable") %>%
  mutate(variable = factor(variable, levels = c("n_total","n_mitigation","n_nature","n_societal"),
                           labels = c("All articles","Mitigation","Natural resilience","Societal\nadaptation")))

# Model fit
mod <- lm(log(n_total)~year, data = n_relevant, subset = n_total > 0)
pred_df <- data.frame(year = seq(min(n_relevant$year), max(n_relevant$year), by=1))
pred_y <- predict(mod, pred_df, interval = "confidence", type="response")
pred_df <- cbind(pred_df, as.data.frame(exp(pred_y)))
  
formula_text <- data.frame(
  label = paste0("y == ", 
                 format(coef(mod)[1], scientific=TRUE, digits = 2), "*(",
                 format(coef(mod)[2], scientific=TRUE, digits = 2),"^x)"),
  year=as.Date("1960-01-01"),
  y=max(n_relevant$n_total)
)



## Research areas

# tabulate the number of different research areas in a year and
# filter the tabulated results to just the high-sampled research areas

# tabulate
years <- unique(research_area_df$year)
for(y in 1:length(years)){
  tempList <- strsplit(research_area_df$research_areas[research_area_df$year == years[y]],split = "; ")
  tempTab <- as.data.frame(table(unlist(lapply(tempList, unique))))
  tempTab$year <- years[y]
  if(y==1)
    research_area_tab <- tempTab
  else
    research_area_tab <- rbind(research_area_tab, tempTab)
}
# rename columns
research_area_tab$year <- as.Date(paste0(research_area_tab$year,"-01-01"))
research_area_tab <- research_area_tab%>%
  rename(research_area = Var1, n_articles = Freq)
# Find which research areas are in the higher percentile
low_research_areas <- research_area_tab %>%
  group_by(research_area) %>%
  summarise(n_articles=sum(n_articles)) %>%
  ungroup()%>%
  arrange(desc(n_articles)) %>%
  slice(1:10) %>%
  arrange(research_area)
raLevels <- as.character(low_research_areas$research_area)

# subset
research_area_tab <- research_area_tab %>%
  filter(year < as.Date("2023-01-01")) %>%
  mutate(research_area = ifelse(research_area %in% raLevels,
                                as.character(research_area), "Other")) %>% 
  mutate(research_area = factor(research_area, levels = c(raLevels, "Other")))

# Calculate as a proportion of total articles
yearlyTotal <- research_area_tab %>%
  group_by(year) %>%
  summarise(yearlyTotal = sum(n_articles))

research_area_tab <- research_area_tab %>%
  merge(yearlyTotal, by="year")%>%
  mutate(proportion = n_articles/yearlyTotal)



## PLOT

## Annual trend in number of articles
annualTrend_ggp2 <- ggplot()+
  geom_ribbon(data=n_relevant, aes(x=year, ymin = n_lower, ymax = n_upper), fill = "lightgrey")+
  geom_line(data = n_relevant_melt, aes(x=year, y=mean_prediction, col = variable), linewidth = 1)+
  geom_line(data = pred_df, aes(x=year, y=fit), col="red", linetype = "dashed", linewidth = 1)+
  geom_text(data=formula_text, aes(x=year, y=y, 
                                   label = label),parse=TRUE, color = "red")+
  geom_text(data=formula_text, aes(x=year, y=y-1000, 
                                   label = paste("R^2 == ",
                                                 format(summary(mod)$adj.r.squared, digits = 2))),
            color = "red", parse=TRUE)+
  scale_color_manual(values = c("black",as.vector(branchPal)), 
                     name = "Mean predicted\nrelevance")+
  labs(x="Year", y="Articles predicted relevant (n)")+
  scale_x_date()+
  theme_classic()+
  theme(legend.position = "right")

annualTrend_ggp2

## Annual trend in the articles by research area
annualResearchArea_ggp <- ggplot()+
  geom_col(data = research_area_tab, aes(x=year, y=n_articles, fill=research_area),
           position = "stack")+
  scale_x_date()+
  scale_fill_brewer(type = "qual",palette = "Paired")+
  labs(y="Articles predicted relevant (n)",x="Year",
       fill= "Research\narea")+
  theme_classic()+
  theme(legend.position = "right")
  

annualResearchArea_ggp


# Show as a proportion

annualResearchAreaProportion_ggp <- research_area_tab %>%
  ggplot()+
  geom_col(aes(x=year, y=proportion, fill=research_area),
           position = "stack")+
  scale_x_date(limits = c(as.Date("1990-01-01"),as.Date("2022-01-01")))+
  scale_fill_brewer(type = "qual",palette = "Paired")+
  labs(y="Proportional contribution",x="Year",
       fill= "Research\narea")+
  theme_classic()+
  theme(legend.position = "right")
  




pdf(here::here("figures/main/annual-trends-research-area.pdf"),
    width = 7, height=6)
egg::ggarrange(annualTrend_ggp2, annualResearchAreaProportion_ggp,
          nrow=2, ncol=1, newpage = FALSE, labels = c("a.","b."))
dev.off()
```

```{r trend in research area by oro branch}

## SQLITE CALCULATIONS
# connect to db and load tables
all_db <- RSQLite::dbConnect(RSQLite::SQLite(),all_db_fp, create=FALSE)
dedups <- tbl(all_db,"uniquerefs") %>% filter(!is.na(abstract))
predBranch <- tbl(all_db, "predBranch")

# Get the number of articles that are relevant, for any ORO branch
# and their metadata
research_area_branch_df <- predBranch %>%
  filter(0.5 <= Mitigation_upper |
           0.5 <= Nature_upper |
           0.5 <= Societal_upper) %>%
  left_join(dedups, by="analysis_id") %>%
  filter(!is.na(research_areas)) %>%
  select(analysis_id, duplicate_id, research_areas, year, 
         Mitigation_upper, Nature_upper, Societal_upper)%>%
  filter(!is.na(year)) %>%
  collect()


# Disconnect the database
dbDisconnect(all_db)


## LOAD OECD REASEARCH AREA CLASSIFICATIONS
oecdCat <- readxl::read_xlsx(here::here("data/raw-data/research-area-schemas/OECD-Category-Mapping.xlsx"))
oecdCat <- oecdCat[,c(1,3)]
colnames(oecdCat) <- c("OECD_research_area","research_area_upper")
oecdCat$OECD_level = readr::parse_number(oecdCat$OECD_research_area)
oecdCat$OECD_high_level = floor(oecdCat$OECD_level)
oecdCatHighLevel <- oecdCat[,c("OECD_research_area","OECD_level")]
oecdCatHighLevel <- oecdCatHighLevel[!duplicated(oecdCatHighLevel),]
oecdCatHighLevel <- oecdCatHighLevel[which(oecdCatHighLevel$OECD_level %in% c(1:6)),]
colnames(oecdCatHighLevel)[1] <- "OECD_research_area_high"
oecdCat <- oecdCat %>% left_join(oecdCatHighLevel, by="OECD_level")
oecdCat <- oecdCat[!duplicated(oecdCat[,c("research_area_upper","OECD_research_area_high")]),]
oecdCat <- oecdCat %>% arrange("OECD_level")

research_area_tab %>%
  head() %>%
  mutate(research_area_upper = toupper(research_area))%>%
  left_join(oecdCat, by="research_area_upper")



## CALCULATIONS

# tabulate the number of different research areas in a year and branch,
# filter the tabulated results to just the high-sampled research areas

# Format the columns
research_area_branch_df <- research_area_branch_df %>% 
  mutate(research_areas = eval(parse(text=gsub("\\", "", deparse(research_areas), fixed=TRUE)))) 

research_area_branch_df_melt <- reshape2::melt(
  research_area_branch_df, measure.vars = c("Mitigation_upper", "Nature_upper", "Societal_upper"),
  value.name = "relevance_upper", variable.name = "ORO_branch"
)
# make sure only keep the rows that are predicted relevant for that particular branch
research_area_branch_df_melt <- research_area_branch_df_melt %>%
  filter(0.5 <= relevance_upper)

research_area_branch_df_melt$ORO_branch <- factor(
  research_area_branch_df_melt$ORO_branch,
  levels = c("Mitigation_upper", "Nature_upper", "Societal_upper"),
  labels = c("Mitigation","Natural resilience","Societal adaptation"))

# Loop through all the unique year and branch combinations to tabulate the research areas
years <- unique(research_area_df$year) 
branches <- levels(research_area_branch_df_melt$ORO_branch) 
for(y in 1:length(years)){
  for(b in 1:length(branches)){
    # Tabulate appearances of each unique research area for that year and branch
    tempList <- strsplit(
      research_area_branch_df_melt$research_areas[
        research_area_branch_df_melt$year == years[y] &
          research_area_branch_df_melt$ORO_branch == branches[b]],
      split = "; ")
    if(length(tempList)==0){
      next
    }
    
    tempTab <- as.data.frame(table(unlist(lapply(tempList, unique))))
    # match to get to OCED level
    matches <- sapply(toupper(tempTab$Var1), function(x) grep(x, oecdCat$research_area_upper))
    if(!("list" %in% class(matches))){
      matches <- list(as.vector(matches))
    }
    tempTab$oecd_research_area <- oecdCat$OECD_research_area_high[
      sapply(matches, function(x) ifelse(length(x)==0, NA, min(x)))]
    
    # If no match, separate by "&" symbol and look for individual matches
    # Start by separating dataframes to only investigate NAs
    noMatch <- subset(tempTab, is.na(oecd_research_area))
    tempTab <- subset(tempTab, !is.na(oecd_research_area))
    # Get new research areas by splitting at &
    newRAs <- unlist(strsplit(as.character(noMatch$Var1),split='&',fixed=TRUE))
    newRAs <- trimws(newRAs, which = c("both"))
    # Match elongated dataframe with old frequencies
    matches <- sapply(newRAs, function(x) grep(x, noMatch$Var1))
    newFreq <- unlist(sapply(matches, function(x) sum(noMatch$Freq[x], na.rm=T)))
    noMatch <- data.frame(
     Var1 = newRAs,
     Freq = newFreq
    )
    rownames(noMatch) <- NULL
    noMatch <- subset(noMatch, Var1 != "Science") # Too broad
    # Look for OECD match
    matches <- sapply(toupper(noMatch$Var1), function(x) grep(x, oecdCat$research_area_upper))
    if(length(matches)==0){next} # if no matches, continue
    if(sum(sapply(matches, function(x) length(x))) == 0){next} # if no matches, continue
    noMatch$oecd_research_area <- oecdCat$OECD_research_area_high[
      sapply(matches, function(x) ifelse(length(x)==0, NA, min(x)))]
    noMatch <- na.omit(noMatch)
    
    # Bind dataframes back together and Join
    tempTab <- rbind(tempTab, noMatch)
    tempTab$year <- years[y]
    tempTab$ORO_branch <- branches[b]
    if(y==1 & b==1)
      research_area_branch_tab <- tempTab
    else
      research_area_branch_tab <- rbind(research_area_branch_tab, tempTab)
  }
}

# rename columns
research_area_branch_tab$year <- as.Date(paste0(research_area_branch_tab$year,"-01-01"))
research_area_branch_tab$ORO_branch <- factor(research_area_branch_tab$ORO_branch,
                                              levels = branches)
research_area_branch_tab <- research_area_branch_tab%>%
  rename(research_area = Var1, n_articles = Freq)

research_area_branch_tab$oecd_research_area <- factor(
  research_area_branch_tab$oecd_research_area, 
  levels = oecdCatHighLevel$OECD_research_area_high[order(oecdCatHighLevel$OECD_level)]
)

# # Find which are the top n research areas for each branch overall
# low_research_branch_areas <- research_area_branch_tab %>%
#   group_by(research_area, ORO_branch) %>%
#   summarise(n_articles=sum(n_articles)) %>%
#   ungroup() %>%
#   arrange(desc(n_articles)) %>%
#   group_by(ORO_branch) %>%
#   slice(1:7)
# length(unique(low_research_branch_areas$research_area)) # number of total research areas
# raLevels <- unique(low_research_branch_areas$research_area)[order(unique(low_research_branch_areas$research_area))]
# raLevels <- as.character(raLevels)
# 
# # subset -- all other research areas put into the "other" category
# research_area_branch_tab <- research_area_branch_tab %>%
#   filter(year < as.Date("2023-01-01")) %>%
#   mutate(research_area = ifelse(research_area %in% raLevels,
#                                 as.character(research_area), "Other")) %>% 
#   mutate(research_area = factor(research_area, levels = c(raLevels, "Other"))) 



# Calculate the number of articles as a proportion of the total
yearlyBranchTotal <- research_area_branch_tab %>%
  group_by(year, ORO_branch) %>%
  summarise(totalArticles = sum(n_articles))

research_area_branch_tab <- research_area_branch_tab %>%
  merge(yearlyBranchTotal, by=c("year","ORO_branch")) %>%
  mutate(proportion = n_articles/totalArticles)


## PLOT
annualResearchAreaProportionBranch_ggp <- research_area_branch_tab %>%
  ggplot()+
  facet_grid(ORO_branch~.)+
  geom_col(aes(x=year, y=proportion, fill=research_area),
           position = "stack")+
  scale_x_date(limits = c(as.Date("1990-01-01"), as.Date("2022-01-01")))+
  scale_fill_brewer(type = "qual",palette = "Paired")+
  labs(y="Proportional contribution",x="Year",
       fill= "Research\narea")+
  theme_classic()+
  theme(legend.position = "right")

annualResearchAreaProportionBranch_oecd_ggp <- research_area_branch_tab %>%
  ggplot()+
  facet_grid(ORO_branch~.)+
  geom_col(aes(x=year, y=proportion, fill=oecd_research_area),
           position = "stack")+
  scale_x_date(limits = c(as.Date("1990-01-01"), as.Date("2022-01-01")))+
  scale_fill_brewer(type = "qual",palette = "Paired")+
  labs(y="Proportional contribution",x="Year",
       fill= "Research\narea")+
  theme_classic()+
  theme(legend.position = "right")
  
annualResearchAreaProportionBranch_ggp
annualResearchAreaProportionBranch_oecd_ggp


ggsave(here::here("figures/supplementary/annual-trends-branch-research-area.pdf"), 
       plot = annualResearchAreaProportionBranch_ggp, width = 7, height=6, units="in")

ggsave(here::here("figures/supplementary/annual-trends-branch-oecd-research-area.pdf"), 
       plot = annualResearchAreaProportionBranch_oecd_ggp, width = 7, height=6, units="in")

```


```{r Map of First Author Affiliation}
## SQLITE CALCULATIONS
# connect to db and load tables
all_db <- RSQLite::dbConnect(RSQLite::SQLite(),all_db_fp, create=FALSE)
dedups <- tbl(all_db,"uniquerefs") %>% filter(!is.na(abstract))
predRel <- tbl(all_db, "predRel2") 

# Get the number of articles that are relevant, and their metadata
affiliation_df <- predRel %>%
  filter(0.5 <= relevance_upper) %>%
  left_join(dedups, by="analysis_id") %>%
  filter(!is.na(affiliation)) %>%
  select(analysis_id, duplicate_id, affiliation)%>%
  collect()

# Disconnect the database
dbDisconnect(all_db)



## DATA FORMATTING
world_map <- map_data("world")

# look for matches between each full affiliatoin and a region in the world map
affiliation_df$region <- rep(NA, nrow(affiliation_df))
regions <- unique(world_map$region)
for(r in 1:length(regions)){
  matches <- grepl(regions[r], affiliation_df$affiliation,ignore.case = TRUE)
  affiliation_df$region[matches] <- regions[r]
}
sum(is.na(affiliation_df$region)) # no matches - 10678
sum(!is.na(affiliation_df$region)) # compared to # of matches - 46911

# Calculate the number of affiliations for each region
library(ggthemes)
affiliation_df_tab <- affiliation_df %>%
  group_by(region) %>%
  summarise(n_articles = n()) %>%
  right_join(world_map %>% filter(! long > 180), by = "region")


ggplot(data=affiliation_df_tab, aes(long, lat, group=group, fill = n_articles))+
  geom_polygon()+
  scale_fill_viridis_c()+
  coord_map("moll") 

lout = 100
bb <- data.frame(
  long = c(seq(-180,180,length.out = lout),
           rep(180, lout),
           seq(180,-180, length.out = lout),
           rep(-180, lout)),
  lat = c(rep(-90, lout),
          seq(-90,90,length.out = lout),
          rep(90, lout),
          seq(90,-90, length.out = lout))
)
bb$group <- paste("boundingBox")


affiliationMap_ggp <- ggplot()+
  geom_polygon(data = affiliation_df_tab, aes(long, lat, group=group, fill = n_articles))+
  geom_polygon(data = bb, aes(long, lat, group=group), col="black", fill = "transparent")+
  scale_fill_viridis_c(name = "Number of articles")+
  coord_map("moll") +
  theme_map()+
  theme(legend.position = "bottom", legend.key.width = unit(0.5, units = "in"))


# Another option for improvement could be this:
# https://seethedatablog.wordpress.com/2016/12/23/r-simple-world-map-robinson-ggplot/

```


```{r Save Annual trends research area and affiliation map multipanel}
## SQLITE CALCULATIONS -------------------
# connect to db and load tables
all_db <- RSQLite::dbConnect(RSQLite::SQLite(),all_db_fp, create=FALSE)
dedups <- tbl(all_db,"uniquerefs") %>% filter(!is.na(abstract))
predRel <- tbl(all_db, "predRel2") 
predBranch <- tbl(all_db, "predBranch")

# Get the number of relevant predictions for each year
n_relevant <- predRel %>%
  left_join(dedups, by="analysis_id") %>%
  left_join(predBranch, by = "analysis_id") %>%
  filter(!is.na(year)) %>%
  group_by(year) %>%
  summarise(n_lower = sum(0.5 <= relevance_lower),
            n_total = sum(0.5 <= relevance_mean),
            n_upper = sum(0.5 <= relevance_upper),
            n_mitigation = sum(0.5 <= Mitigation_mean & 0.5 <= relevance_mean),
            n_nature = sum(0.5 <= Nature_mean & 0.5 <= relevance_mean),
            n_societal = sum(0.5 <= Societal_mean & 0.5 <= relevance_mean)) %>%
  collect()


# Get the research area for relevant articles
research_area_df <- predRel %>%
  filter(0.5 <= relevance_upper) %>%
  left_join(dedups, by="analysis_id") %>%
  filter(!is.na(research_areas)) %>%
  select(analysis_id, duplicate_id, research_areas, web_of_science_categories, year)%>%
  filter(!is.na(year)) %>%
  mutate(research_areas = eval(parse(text=gsub("\\", "", deparse(research_areas), fixed=TRUE))),
         first_research_area = gsub("\\;.*","", research_areas)) %>%
  collect()


# Get the affiliation metadata for relevant articles
affiliation_df <- predRel %>%
  filter(0.5 <= relevance_upper) %>%
  left_join(dedups, by="analysis_id") %>%
  filter(!is.na(affiliation)) %>%
  select(analysis_id, duplicate_id, affiliation)%>%
  collect()

# Disconnect the database
dbDisconnect(all_db)



## PLOT 1: Annual trends in # of relevant articles ------------------

## Data formatting & Calculations


# year as date
n_relevant$year <- as.Date(paste0("01-01-", n_relevant$year), format = "%d-%m-%Y")
n_relevant <- n_relevant %>% filter(year < as.Date("01-01-2023", format = "%d-%m-%Y"))
# Melt by ORO branch
n_relevant_melt <- reshape2::melt(n_relevant, measure.vars = c("n_total","n_mitigation","n_nature","n_societal"),
                     value.name = "mean_prediction", variable.name = "variable") %>%
  mutate(variable = factor(variable, levels = c("n_total","n_mitigation","n_nature","n_societal"),
                           labels = c("All articles","Mitigation","Natural resilience","Societal\nadaptation")))
# Model fit
mod <- lm(log(n_total)~year, data = n_relevant, subset = n_total > 0)
pred_df <- data.frame(year = seq(min(n_relevant$year), max(n_relevant$year), by=1))
pred_y <- predict(mod, pred_df, interval = "confidence", type="response")
pred_df <- cbind(pred_df, as.data.frame(exp(pred_y)))
# Dataframe of where to write the model text on the plot
formula_text <- data.frame(
  label = paste0("y == ", 
                 format(coef(mod)[1], scientific=TRUE, digits = 2), "*(",
                 format(coef(mod)[2], scientific=TRUE, digits = 2),"^x)"),
  year=as.Date("1960-01-01"),
  y=max(n_relevant$n_total)
)


## Plotting
## Annual trend in number of articles
annualTrend_ggp2 <- ggplot()+
  geom_ribbon(data=n_relevant, aes(x=year, ymin = n_lower, ymax = n_upper), fill = "lightgrey")+
  geom_line(data = n_relevant_melt, aes(x=year, y=mean_prediction, col = variable), linewidth = 1)+
  geom_line(data = pred_df, aes(x=year, y=fit), col="red", linetype = "dashed", linewidth = 1)+
  geom_text(data=formula_text, aes(x=year, y=y, 
                                   label = label),parse=TRUE, color = "red")+
  geom_text(data=formula_text, aes(x=year, y=y-1000, 
                                   label = paste("R^2 == ",
                                                 format(summary(mod)$adj.r.squared, digits = 2))),
            color = "red", parse=TRUE)+
  scale_color_manual(values = c("black",as.vector(branchPal)), 
                     name = "Mean predicted\nrelevance")+
  labs(x="Year", y="Articles predicted relevant (n)")+
  scale_x_date()+
  theme_classic()+
  theme(legend.position = "right")




## PLOT 2: Contribution of different research areas -------------------------------

## Data Formatting and Calculations

# tabulate the number of different research areas in a year and
# filter the tabulated results to just the high-sampled research areas
# tabulate

# Try mapping WOS research areas (252 categories) to OECD category scheme which are only ~45
# http://help.prod-incites.com/inCites2Live/filterValuesGroup/researchAreaSchema/oecdCategoryScheme.html
oecdCat <- readxl::read_xlsx(here::here("data/raw-data/research-area-schemas/OECD-Category-Mapping.xlsx"))
oecdCat <- oecdCat[,c(1,3)]
colnames(oecdCat) <- c("OECD_research_area","research_area_upper")
oecdCat$OECD_level = readr::parse_number(oecdCat$OECD_research_area)
oecdCat$OECD_high_level = floor(oecdCat$OECD_level)
oecdCatHighLevel <- oecdCat[,c("OECD_research_area","OECD_level")]
oecdCatHighLevel <- oecdCatHighLevel[!duplicated(oecdCatHighLevel),]
oecdCatHighLevel <- oecdCatHighLevel[which(oecdCatHighLevel$OECD_level %in% c(1:6)),]
colnames(oecdCatHighLevel)[1] <- "OECD_research_area_high"
oecdCat <- oecdCat %>% left_join(oecdCatHighLevel, by="OECD_level")
oecdCat <- oecdCat[!duplicated(oecdCat[,c("research_area_upper","OECD_research_area_high")]),]
oecdCat <- oecdCat %>% arrange("OECD_level")

research_area_tab %>%
  head() %>%
  mutate(research_area_upper = toupper(research_area))%>%
  left_join(oecdCat, by="research_area_upper")

years <- unique(research_area_df$year)
for(y in 1:length(years)){
  # Tabulate appearances of each unique research area for that year
  tempList <- strsplit(research_area_df$research_areas[research_area_df$year == years[y]],split = "; ")
  tempTab <- as.data.frame(table(unlist(lapply(tempList, unique))))
  # match to get to OCED level
  matches <- sapply(toupper(tempTab$Var1), function(x) grep(x, oecdCat$research_area_upper))
  tempTab$oecd_research_area <- oecdCat$OECD_research_area_high[
    sapply(matches, function(x) ifelse(length(x)==0, NA, min(x)))]
  
  # If no match, separate by "&" symbol and look for individual matches
  # Start by separating dataframes to only investigate NAs
  noMatch <- subset(tempTab, is.na(oecd_research_area))
  tempTab <- subset(tempTab, !is.na(oecd_research_area))
  # Get new research areas by splitting at &
  newRAs <- unlist(strsplit(as.character(noMatch$Var1),split='&',fixed=TRUE))
  newRAs <- trimws(newRAs, which = c("both"))
  # Match elongated dataframe with old frequencies
  matches <- sapply(newRAs, function(x) grep(x, noMatch$Var1))
  newFreq <- unlist(sapply(matches, function(x) sum(noMatch$Freq[x], na.rm=T)))
  noMatch <- data.frame(
   Var1 = newRAs,
   Freq = newFreq
  )
  rownames(noMatch) <- NULL
  noMatch <- subset(noMatch, Var1 != "Science") # Too broad
  # Look for OECD match
  matches <- sapply(toupper(noMatch$Var1), function(x) grep(x, oecdCat$research_area_upper))
  if(sum(sapply(matches, function(x) length(x))) == 0){next} # if no matches, continue
  noMatch$oecd_research_area <- oecdCat$OECD_research_area_high[
    sapply(matches, function(x) ifelse(length(x)==0, NA, min(x)))]
  noMatch <- na.omit(noMatch)
  
  # Bind dataframes back together and Join
  tempTab <- rbind(tempTab, noMatch)
  tempTab$year <- years[y]
  if(y==1)
    research_area_tab <- tempTab
  else
    research_area_tab <- rbind(research_area_tab, tempTab)
}
# rename columns
research_area_tab$year <- as.Date(paste0(research_area_tab$year,"-01-01"))
research_area_tab <- research_area_tab%>% rename(research_area = Var1, n_articles = Freq)
research_area_tab$oecd_research_area <- factor(
  research_area_tab$oecd_research_area, 
  levels = oecdCatHighLevel$OECD_research_area_high[order(oecdCatHighLevel$OECD_level)]
)

# # Find which research areas are in the higher percentile
# low_research_areas <- research_area_tab %>%
#   group_by(research_area) %>%
#   summarise(n_articles=sum(n_articles)) %>%
#   ungroup()%>%
#   arrange(desc(n_articles)) %>%
#   slice(1:10) %>%
#   arrange(research_area)
# raLevels <- as.character(low_research_areas$research_area)
# # Format the research area factor to just the highest levels and group others into "Other"
# research_area_tab <- research_area_tab %>%
#   filter(year < as.Date("2023-01-01")) %>%
#   mutate(research_area = ifelse(research_area %in% raLevels,
#                                 as.character(research_area), "Other")) %>% 
#   mutate(research_area = factor(research_area, levels = c(raLevels, "Other")))

# Calculate as a proportion of total articles
yearlyTotal <- research_area_tab %>%
  group_by(year) %>%
  summarise(yearlyTotal = sum(n_articles))

research_area_tab <- research_area_tab %>%
  merge(yearlyTotal, by="year")%>%
  mutate(proportion = n_articles/yearlyTotal)


## Plotting
annualResearchAreaProportion_ggp <- research_area_tab %>%
  ggplot()+
  geom_col(aes(x=year, y=proportion, fill=research_area),
           position = "stack")+
  scale_x_date(limits = c(as.Date("1990-01-01"),as.Date("2022-01-01")))+
  scale_fill_brewer(type = "qual",palette = "Paired")+
  labs(y="Proportional contribution",x="Year",
       fill= "Research\narea")+
  theme_classic()+
  theme(legend.position = "right")
  

annualResearchAreaProportion_OECD_ggp <- research_area_tab %>%
  ggplot()+
  geom_col(aes(x=year, y=proportion, fill=oecd_research_area),
           position = "stack")+
  scale_x_date(limits = c(as.Date("1990-01-01"),as.Date("2022-01-01")))+
  #scale_fill_brewer(type = "qual",palette = "Paired",labels = scales::label_wrap(10))+
  labs(y="Proportional contribution",x="Year",
       fill= "OECD\nResearch\narea")+
  theme_classic()+
  theme(legend.position = "bottom")

## PLOT 3: Map of affiliation -------------------------------------------

## DATA FORMATTING
world_map <- map_data("world")

# look for matches between each full affiliatoin and a region in the world map
affiliation_df$region <- rep(NA, nrow(affiliation_df))
regions <- unique(world_map$region)
for(r in 1:length(regions)){
  matches <- grepl(regions[r], affiliation_df$affiliation,ignore.case = TRUE)
  affiliation_df$region[matches] <- regions[r]
}
sum(is.na(affiliation_df$region)) # no matches - 10678
sum(!is.na(affiliation_df$region)) # compared to # of matches - 46911

# Calculate the number of affiliations for each region
library(ggthemes)
affiliation_df_tab <- affiliation_df %>%
  group_by(region) %>%
  summarise(n_articles = n()) %>%
  right_join(world_map %>% filter(! long > 180), by = "region")


ggplot(data=affiliation_df_tab, aes(long, lat, group=group, fill = n_articles))+
  geom_polygon()+
  scale_fill_viridis_c()+
  coord_map("moll") 

lout = 100
bb <- data.frame(
  long = c(seq(-180,180,length.out = lout),
           rep(180, lout),
           seq(180,-180, length.out = lout),
           rep(-180, lout)),
  lat = c(rep(-90, lout),
          seq(-90,90,length.out = lout),
          rep(90, lout),
          seq(90,-90, length.out = lout))
)
bb$group <- paste("boundingBox")


affiliationMap_ggp <- ggplot()+
  geom_polygon(data = affiliation_df_tab, aes(long, lat, group=group, fill = n_articles))+
  geom_polygon(data = bb, aes(long, lat, group=group), col="black", fill = "transparent")+
  scale_fill_viridis_c(name = "Number of articles")+
  coord_map("moll") +
  theme_map()+
  theme(legend.position = "bottom", legend.key.width = unit(0.5, units = "in"))


# Another option for improvement could be this:
# https://seethedatablog.wordpress.com/2016/12/23/r-simple-world-map-robinson-ggplot/
mat <- rbind(c(1,3),c(2,2))

pdf(here::here("figures/main/annual-trends-research-area-affiliation.pdf"),
    width = 10, height=6)
gridExtra::grid.arrange(annualTrend_ggp2+ggtitle("a."), annualResearchAreaProportion_ggp+ggtitle("c.")+guides(fill = guide_legend(ncol = 2, byrow = TRUE)), affiliationMap_ggp+ggtitle("b."),
          layout_matrix = mat)
while(!is.null(dev.list())) dev.off()


## NOTE that the counts of the branches are conditional on predicted relevance mean prediction, otherwise the mitigation mean line surpasses the mean line of all the articles and it looks confusing

```



```{r Save Annual trends research area and oro_type barplot multipanel}
## LOAD DATA
## Read in the predictions for oro_type
# Note these predictions were made using the upper confidence limit for ORO_branch
oroAnyFiles <- dir(here::here("data/raw-data/coding-predictions"))
oroAnyFiles <- oroAnyFiles[grep("oro_any", oroAnyFiles)]
predOROAnyList <- list()
for(i in 1:length(oroAnyFiles)){
  temp <- readr::read_csv(
    here::here("data/raw-data/coding-predictions",oroAnyFiles[i]),
    show_col_types = FALSE
  )
  colNames <- colnames(temp)
  colNames[1] <- "analysis_id"
  colNames <- gsub("oro_any.","",colNames)
  colNames <- gsub("M_","", colNames)
  colNames <- gsub("N_","", colNames)
  colNames <- gsub("SA_","", colNames)
  colNames <- gsub(" - ","_", colNames)
  colNames <- gsub("_prediction","", colNames)
  colNames <- gsub("_pred","", colNames)
  colnames(temp) <- colNames
  temp$oro_branch <- gsub("oro_any_","",oroAnyFiles[i])
  temp$oro_branch <- gsub("_predictions.csv","",temp$oro_branch)
  predOROAnyList[[i]] <- temp
}

## Make a dataframe of the predictions
for(i in 1:length(predOROAnyList)){
  temp <- predOROAnyList[[i]]
  boundaries <- c("upper","mean","lower")
  for(b in 1:length(boundaries)){
    temp_b <- cbind(temp[,1], temp$oro_branch, temp[grep(boundaries[b], colnames(temp))])
    colnames(temp_b)[2]<- "oro_branch"
    colnames(temp_b) <- gsub(paste0("_",boundaries[b]),"", colnames(temp_b))
    temp_b <- reshape2::melt(temp_b, variable.name = "oro_any", value.name = boundaries[b], 
                             id.vars = c("analysis_id","oro_branch"))
    if(b==1){
      temp_melt <- temp_b
    }else{
      temp_melt <- merge(temp_melt, temp_b, by=c("analysis_id","oro_branch","oro_any"))
    }
  }
  if(i==1)
    predOROAny <- temp_melt
  else
    predOROAny <- rbind(predOROAny, temp_melt)
}
rm(predOROAnyList)


## BARPLOT OF NUMBER OF ARTICLES PREDICTED RELEVANT FOR EACH TYPE
temp <- predOROAny %>%
  mutate(oro_branch = factor(oro_branch,
                             levels = c("mitigation","nature","societal"),
                             labels = c("Mitigation","Natural resilience","Societal adaptation"))) %>%
  group_by(oro_branch, oro_any)%>%
  summarise(n_mean = sum(0.5 <= mean),
            n_lower = sum(0.5 <= lower),
            n_upper = sum(0.5 <= upper))%>%
  arrange(oro_branch,n_mean)%>%
  ungroup()%>%
  mutate(valueOrder = as.factor(row_number()))
  
numberOROTypeBar_ggp <- ggplot(temp, aes(x=valueOrder, y=n_mean, fill = oro_branch))+
  geom_col()+
  geom_errorbar(aes(ymin = n_lower, ymax = n_upper), width=.2)+
  geom_text(aes(label = n_mean), nudge_y = 1000, size=3, col="red")+ #nudge_x=0.2,
  scale_fill_manual(name = "ORO Branch", values = as.vector(branchPal))+
  scale_x_discrete(limits = levels(temp$valueOrder), 
                    labels = gsub("_"," ", temp$oro_any[order(temp$valueOrder)]))+
  #ylim(c(0, max(temp$n_upper)+2000))+
  labs(y="Articles predicted relevant (n)")+
  theme(
    panel.background = element_rect(fill="white",colour = "black"),
    panel.grid.major = element_line(colour = "grey"),
    axis.text.x = element_text(angle=45, hjust=1),
    axis.title.x = element_blank()
  )


mat <- rbind(c(1,3),c(2,2))

pdf(here::here("figures/main/annual-trends-research-area-nType.pdf"),
    width = 10, height=8)
gridExtra::grid.arrange(
  annualTrend_ggp2+ggtitle("a.")+
    theme(plot.margin = unit(c(0.1,0,2,0.1), "cm"),legend.position = "bottom")+
    guides(color = guide_legend(nrow = 2, byrow = TRUE)),
  annualResearchAreaProportion_ggp+ggtitle("c.")+guides(fill = guide_legend(ncol = 2, byrow = TRUE)),
  numberOROTypeBar_ggp+ggtitle("b.")+theme(legend.position = "bottom"),
  
  layout_matrix = mat, heights = c(5,3), widths = c(4.5,5.5))
while(!is.null(dev.list())) dev.off()

```

```{r Save annual trends oecd research area oro_type barplot and affiliation map multipanel}

oro_legend <- ggpubr::get_legend(
  annualTrend_ggp2+
    scale_color_manual(values = c("black",as.vector(branchPal)),
                       labels = c("All branches","Mitigation","Natural resilience",
                                  "Societal adaptation"),
                       name = "ORO branch")+
    theme(legend.position = "bottom",
          legend.key.width = unit(0.5,"in"),
          legend.text = element_text(size = 12),
          legend.title = element_text(size = 14))+
    guides(color = guide_legend(nrow = 1, byrow = TRUE, override.aes = list(linewidth = 10)))
  )
oro_legend <- ggpubr::as_ggplot(oro_legend)


while(!is.null(dev.list())) dev.off()

mat <- rbind(c(1,2),
             c(5,5),
             c(3,4))

pdf(here::here("figures/main/annual-trends-oecd-research-area-oroType-affiliation-map.pdf"), width = 10, height=10)
gridExtra::grid.arrange(
  
  annualTrend_ggp2+
    ggtitle("a.")+
    scale_y_continuous(label = scales::unit_format(scale = 0.001,unit = "K"))+
    theme(plot.margin = unit(c(0.1,0,2.5,0.1), "cm"),
          legend.position = "none",
          title = element_text(size=14)), #"bottom" 
    #guides(color = guide_legend(nrow = 2, byrow = TRUE)),
  
  numberOROTypeBar_ggp+
    ggtitle("b.")+
    scale_y_continuous(label = scales::unit_format(scale = 0.001,unit = "K"))+
    theme(legend.position = "none",
          plot.margin = unit(c(0,0.1,0,0.1), "cm"),
          title = element_text(size=14)), # "bottom
  
  annualResearchAreaProportion_OECD_ggp+
    scale_fill_brewer(type = "qual",palette = "Paired",labels = scales::label_wrap(15))+
    ggtitle("c.")+
    theme(plot.margin = unit(c(0.8,0,0,0.1), "cm"),
          title = element_text(size=14))+
    guides(fill = guide_legend("",nrow = 2, byrow = TRUE)),
  
  affiliationMap_ggp+
    ggtitle("d.")+
    theme(plot.margin = unit(c(0,0,1,0), "cm"),
          legend.key.height = unit(1,"cm"),
          legend.key.width = unit(0.75,"in"),
          title = element_text(size=14))+
    guides(fill = guide_colourbar("Number\nof articles")),
  
  oro_legend,
  
  layout_matrix = mat, heights = c(4.5,0.5,4), widths = c(5,5))

while(!is.null(dev.list())) dev.off()

```


# 2. Verifying model fit

```{r performance of DistilBERT vs SVM, echo=FALSE, fig.cap="Performance of DistilBERT vs SVM", out.width = '100%'}
knitr::include_graphics(here::here("figures/supplementary/relevance-predictions-SVM-vs-DistilBERT.png"))
```

## 2.1 Violin plots comparing predicted relevance to reviewer choice for seen articles

```{r violin plots of predicted relevance for seen articles}

## SQLITE CALCULATIONS
# connect to db and load tables
all_db <- RSQLite::dbConnect(RSQLite::SQLite(),all_db_fp, create=FALSE)
dedups <- tbl(all_db,"uniquerefs") %>% filter(!is.na(abstract))
predRel <- tbl(all_db, "predRel2") 
screens <- tbl(all_db, "all-screen-results_screenExcl-codeIncl") %>%
   select(duplicate_id, sample_screen, include_screen)

df <- dedups %>%
  inner_join(predRel, by = "analysis_id") %>%
  inner_join(screens, by = "duplicate_id") %>%
  collect()

summary(df)

# disconnect database
dbDisconnect(all_db)



## PLOT
relevancePredictionsSeenViolin_ggp <- df %>%
  select(sample_screen, include_screen, relevance_lower, relevance_mean, relevance_upper) %>%
  #filter(!(sample_screen == "test list" & include_screen == 0)) %>%
  mutate(sample_screen = factor(ifelse(sample_screen == "test list", "Test list","Other"),
                           levels = c("Test list","Other")),
         include_screen = factor(include_screen, levels = c(1,0), labels = c("include","exclude"))) %>%
  reshape2::melt(
    measure.vars = paste("relevance", c("lower","mean","upper"), sep="_"),
    variable.name = "estimate", value.name = "value"
  ) %>%
  mutate(estimate = factor(estimate, 
                           labels = c(paste0(c("Lower","Mean","Upper"), "\nestimate"))))%>%
  
  ggplot(aes(x=include_screen, y=value, fill = sample_screen)) +
  facet_wrap(vars(estimate))+
  geom_violin(trim=TRUE, aes(colour = sample_screen), linewidth = 0.25)+
  #geom_text(data=tabText, aes(label = `predicted number`), nudge_x = 0.3, size=3, col="red")+
  geom_hline(yintercept = 0.5)+
  scale_y_continuous(limits = c(0,1))+
  labs(fill = "Sample method", colour = "Sample method")+
  labs(x="Reviewer decision", y = "Predicted relevance")+
  theme_bw()+
  theme(
    legend.position = "bottom"
  )


ggsave(here::here("figures/supplementary/relevancePredictions_seen_violin.pdf"), 
       plot = relevancePredictionsSeenViolin_ggp,
       width = 7, height = 4, units="in")
```


```{r violin plots of predicted ORO_branch for seen articles}
## SQLITE CALCULATIONS
# connect to db and load tables
all_db <- RSQLite::dbConnect(RSQLite::SQLite(),all_db_fp, create=FALSE)
predRel <- tbl(all_db, "predRel2") 
predBranch <- tbl(all_db, "predBranch")
codebookCombinedSimplifiedMore <- tbl(all_db, "allCodingSimplifiedVariablesMore")


df <- predRel %>%
  filter(0.5 <= relevance_mean)%>%
  left_join(predBranch, by = "analysis_id") %>%
  left_join(codebookCombinedSimplifiedMore %>%
               select(analysis_id, oro_branch.Mitigation, 
                      oro_branch.Nature, oro_branch.Societal)) %>%
  collect()

summary(df)

# disconnect database
dbDisconnect(all_db)



## DATA FORMATTING AND CALCULATIONS
# melt based on seen decisions for each unit of publication so that each row is a reviewer decision for that article, and then columns for the predictions for each branch
branchDf <- df %>%
  select(analysis_id, relevance_mean, Mitigation_mean, Nature_mean, Societal_mean,
         oro_branch.Mitigation, oro_branch.Nature,oro_branch.Societal)%>%
  reshape2::melt(
    measure.vars = c("oro_branch.Mitigation","oro_branch.Nature","oro_branch.Societal"),
    #measure.vars = c("Mitigation_mean","Nature_mean","Societal_mean"),
    value.name = "seen_branch", variable.name = "oro_branch") %>%
  mutate(oro_branch = factor(oro_branch, 
                             c("oro_branch.Mitigation","oro_branch.Nature",
                               "oro_branch.Societal"),
                             c("Mitigation","Nature","Societal")))%>%
  mutate(seen_branch = ifelse(seen_branch==1, as.character(oro_branch), NA)) %>%
  select(-c(oro_branch)) %>%
  filter(!is.na(seen_branch))

# add a column for the predictions for the branch that was picked when seen
pred <- rep(NA, nrow(branchDf))
for(i in 1:length(pred)){
  if(branchDf$seen_branch[i] == "Mitigation"){
    pred[i] <- branchDf[i, grep("Mitigation", colnames(branchDf), ignore.case = T)]
  }else if(branchDf$seen_branch[i] == "Nature"){
    pred[i] <- branchDf[i, grep("Natur", colnames(branchDf), ignore.case = T)]
  }else if(branchDf$seen_branch[i] == "Societal"){
    pred[i] <- branchDf[i, grep("Societal", colnames(branchDf), ignore.case = T)]
  }else{
    pred[i] <- NA
  }
}
branchDf$seen_branch_pred <- pred; rm(pred)



## PLOTTING
oroBranchPredictionsSeenViolin_ggp <- branchDf %>%
  select(analysis_id, Mitigation_mean, Societal_mean, Nature_mean, seen_branch) %>%
  reshape2::melt(measure.vars = c("Mitigation_mean", "Societal_mean", "Nature_mean"),
                 variable.name = "predictedBranch", value.name = "predictedRelevance")%>% 
  mutate(predictedRelevance = ifelse(0.5 <= predictedRelevance, predictedRelevance, NA),
         predictedBranch = factor(predictedBranch,
                                  levels = c("Mitigation_mean", "Societal_mean", "Nature_mean"),
                                  labels = c("Mitigation","Natural\nresilience",
                                             "Societal\nadaptation")),
         seen_branch = factor(seen_branch,
                              levels = c("Mitigation","Nature","Societal"),
                              labels = c("Mitigation","Natural resilience",
                                             "Societal adaptation"))) %>%
  
  ggplot(aes(x=predictedBranch, y= predictedRelevance, fill=predictedBranch))+
  #geom_hline(yintercept = 0.5)+
  geom_violin()+
  facet_wrap(vars(seen_branch))+
  scale_fill_manual(guide="none", values = as.vector(branchPal))+
  labs(y="Predicted relevance", x = "Predicted ORO branch", fill = "predicted ORO branch")+
  theme_bw()+
  theme(
    axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))
  )
  


ggsave(here::here("figures/supplementary/oro_branchPredictions_seen_violin.pdf"), 
       plot = oroBranchPredictionsSeenViolin_ggp,
       width = 7, height = 4, units="in")

```



Resolving differences between ORO type violin plot

```{r violin plots of predicted ORO type for seen articles using mean}

## READ IN ORO ANY PREDICTIONS AND FORMAT
# Note these predictions were made using the upper confidence limit for ORO_branch
oroAnyFiles <- dir(here::here("data/raw-data/coding-predictions"))
oroAnyFiles <- oroAnyFiles[grep("oro_any", oroAnyFiles)]
predOROAnyList <- list()
for(i in 1:length(oroAnyFiles)){
  temp <- readr::read_csv(
    here::here("data/raw-data/coding-predictions",oroAnyFiles[i]),
    show_col_types = FALSE
  )
  colNames <- colnames(temp)
  colNames[1] <- "analysis_id"
  colNames <- gsub("oro_any.","",colNames)
  colNames <- gsub("M_","", colNames)
  colNames <- gsub("N_","", colNames)
  colNames <- gsub("SA_","", colNames)
  colNames <- gsub(" - ","_", colNames)
  colNames <- gsub("_prediction","", colNames)
  colNames <- gsub("_pred","", colNames)
  colnames(temp) <- colNames
  temp$oro_branch <- gsub("oro_any_","",oroAnyFiles[i])
  temp$oro_branch <- gsub("_predictions.csv","",temp$oro_branch)
  predOROAnyList[[i]] <- temp
}

## Make a dataframe of just the MEAN predictions
boundary = "mean"
for(i in 1:length(predOROAnyList)){
  temp <- predOROAnyList[[i]]
  temp <- temp[grep(boundary, colnames(temp))]
  colnames(temp) <- gsub(paste0("_",boundary),"", colnames(temp))
  temp <- reshape2::melt(temp, variable.name = "oro_any")
  temp <- cbind(predOROAnyList[[i]][,c("analysis_id","oro_branch")], temp)
  if(i==1)
    predOROAny <- temp
  else
    predOROAny <- rbind(predOROAny, temp)
}
rm(predOROAnyList)


## RETREIVE SQLITE METADATA ON SEEN CODING DECISIONS
all_db <- RSQLite::dbConnect(RSQLite::SQLite(),all_db_fp, create=FALSE)
codebookCombinedSimplifiedMore <- tbl(all_db, "allCodingSimplifiedVariablesMore") %>% collect()
dbDisconnect(all_db)




## VIOLIN PLOT COMPARING PREDICTIONS FOR PROTECTION, RESTORATION AND CONSERVATION -----------

## DATA FORMATTING AND CALCULATIONS
# melt based on seen decisions for each unit of publication
# end up with column for analysis id (unique), protection, restoration and conservation, and seen_oro
df <- predOROAny %>%
  filter(oro_any %in% c("Protection","Restoration","Conservation"))%>%
  reshape2::dcast(analysis_id~oro_any, value.var = "value") %>%
  left_join(codebookCombinedSimplifiedMore %>%
               select(analysis_id, oro_any.N_Protection,oro_any.N_Restoration))%>% 
  reshape2::melt(
    measure.vars = c("oro_any.N_Protection","oro_any.N_Restoration"),
    value.name = "seen_oro", variable.name = "oro_any") %>%
  mutate(oro_any = factor(oro_any, 
                             c("oro_any.N_Protection","oro_any.N_Restoration"),
                             c("Protection","Restoration")))%>%
  mutate(seen_oro = ifelse(seen_oro==1, as.character(oro_any), NA)) %>%
  select(-c(oro_any)) 

## PLOTTING
oroType_naturalResilience_PredictionsSeenViolin_ggp <- df %>%
  filter(!is.na(seen_oro))%>%
  reshape2::melt(measure.vars = c("Protection","Restoration","Conservation"),
                 variable.name = "predictedORO", value.name = "predictedRelevance")%>% 
  mutate(predictedRelevance = ifelse(0.5 <= predictedRelevance, predictedRelevance, NA)) %>%
  
  ggplot(aes(x=predictedORO, y= predictedRelevance))+
  geom_violin(fill=as.vector(branchPal[2]))+
  facet_wrap(vars(seen_oro))+
  labs(y="Predicted relevance", x = "Predicted ORO type", fill = "predicted ORO type")+
  theme_bw()+
  theme(
    axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))
  )

ggsave(here::here("figures/supplementary/oro_type_naturalResilience_Predictions_seen_violin.pdf"), 
       plot = oroType_naturalResilience_PredictionsSeenViolin_ggp,
       width = 7, height = 4, units="in")





## VIOLIN PLOT COMPARING PREDICTIONS FOR ALL ORO TYPES -----------

## DATA FORMATTING AND CALCULATIONS
# melt based on seen decisions for each unit of publication
# 1 row = 1 article x seen ORO combinations
oroAnyCols <- colnames(codebookCombinedSimplifiedMore)[
  grep("oro_any", colnames(codebookCombinedSimplifiedMore))]
oroAnyColsLevels <- gsub("oro_any..._","",gsub("oro_any.._","",oroAnyCols))
oroAnyColsLabels <- gsub("_"," ",oroAnyColsLevels)
oroAnyColsLabels[grep("Renew", oroAnyColsLabels)] <- c("Renewable energy")
oroAnyColsLabels[grep("CO", oroAnyColsLabels)] <- c("CO2 removal or storage")
oroAnyColsLabels[grep("Human", oroAnyColsLabels)] <- paste("Human-assisted evolution")
oroAnyColsLabels[grep("Built", oroAnyColsLabels)] <- paste("Built infrastructure & technology")
oroAnyColsLabels[grep("Socio", oroAnyColsLabels)] <- paste("Socio-institutional")



df <- predOROAny %>%
  reshape2::dcast(analysis_id~oro_any, value.var = "value") %>%
  left_join(codebookCombinedSimplifiedMore[c("analysis_id", oroAnyCols)])%>%
  reshape2::melt(
    measure.vars = oroAnyCols,
    value.name = "seen_oro", variable.name = "oro_any") %>%
  mutate(oro_any = factor(oro_any,levels = oroAnyCols,labels = oroAnyColsLabels))%>%
  mutate(seen_oro = ifelse(seen_oro==1, as.character(oro_any), NA)) %>%
  select(-c(oro_any)) 


## PLOTTING
# define colour scale
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

facetCol <- data.frame(
  seen_oro = factor(oroAnyColsLabels, oroAnyColsLabels),
  oroColor = gg_color_hue(length(oroAnyColsLabels))
)

oroTypePredictionsSeenViolin_ggp <- df %>%
  select(-c(Conservation))%>%
  filter(!is.na(seen_oro))%>%
  reshape2::melt(id.vars = c("analysis_id", "seen_oro"),
                 variable.name = "predictedORO", value.name = "predictedRelevance")%>% 
  filter(!is.na(predictedORO))%>%
  mutate(predictedORO = factor(predictedORO, levels = oroAnyColsLevels,labels = oroAnyColsLabels),
         seen_oro = factor(seen_oro, levels = oroAnyColsLabels))  %>%
  # mutate(predictedORO = factor(gsub("_"," ", predictedORO), labels = oroAnyColsLabels),
  #        seen_oro = factor(gsub("_"," ",seen_oro), oroAnyColsLabels))  %>%

  ggplot()+
  geom_hline(yintercept = 0.5)+
  geom_violin(aes(x=predictedORO, y= predictedRelevance, col=predictedORO, fill=predictedORO),
              trim=TRUE, width=1.5, scale = "count", linewidth = 0.5)+
  facet_wrap(vars(seen_oro), labeller= label_wrap_gen(30))+ 
  geom_rect(data=facetCol, aes(xmin=-Inf, xmax=Inf, ymin=1.05, ymax=1.35,
                               fill=seen_oro))+
  coord_cartesian(clip = "off", ylim=c(0,1))+
  labs(y="Predicted relevance", x = "Predicted ORO type",
       guide = "Predicted\nORO type")+
  #scale_fill_discrete(guide="none")+
  scale_fill_manual(guide="none", values = facetCol$oroColor, breaks = facetCol$seen_oro)+
  scale_colour_manual(guide="none", values = facetCol$oroColor, breaks = facetCol$seen_oro)+
  theme(
    panel.background = element_rect(fill="white", colour = "black"),
    panel.grid.major = element_line(colour = "lightgrey"),
    #axis.text.x = element_blank(),
    strip.background = element_rect(fill=NA),
    axis.text.x = element_text(angle=90, hjust=1, vjust=0.5),
    axis.title.x = element_text(margin = margin(t = 10, r = 0, b = 0, l = 0))
  )



ggsave(here::here("figures/supplementary/oro_typePredictions_seen_violin.pdf"), 
       plot = oroTypePredictionsSeenViolin_ggp,
       width = 7, height = 7.5, units="in")


```


## 2.2 Examine correlations and overlaps between variable predictions

blue carbon or co2 removal/storage
```{r are blue carbon and co2 removal and storage oro predictions correlated?}
predCO2 <- readOROAnyPredictions(boundaries = "mean")
predCO2 <- predCO2 %>%
  filter(oro_any == "CO2_removal_or_storage") %>%
  rename(CO2_removal_or_storage = mean) %>%
  select(analysis_id, CO2_removal_or_storage)


predBC <- readPredictions(boundaries = "mean", variable = "blue_carbon")
predBC <- predBC %>%
  select(-c(blue_carbon)) %>%
  rename(blue_carbon = mean) %>%
  select(analysis_id, blue_carbon)

temp_df <- inner_join(predCO2, predBC, by = "analysis_id")

cor(temp_df$CO2_removal_or_storage, temp_df$blue_carbon) # 0.4989678

plot(temp_df$CO2_removal_or_storage, temp_df$blue_carbon) # Not a very strong relationship
```






# Heatmaps of interactions

Calculations to do
- climate threat simplified (temp, SLR, extreme weather) model + predictions.
- ecosystem simplified 2 (Mangrove, Coral, Seagrass, salt marsh) model and predictions
- oro_dev_stage societal - implemented binary (just societal) model and predictions. code prepped




Three way heatmap of Climate threat(temperature, SLR, extreme weather) and adaptation OROs and adaptation outcomes, facetted by continent -- add as inset to map of number of studies?



## ORO type, outcome and data type

Heatmap of ORO type and outcome, coloured by number of articles -- supplement?
In the heatmap above, also change geom_point size depending on number of secondary data types? Data_type primary vs secondary

```{r heatmap of oro type outcome and data type}
## Read in data for plots (cluster by climate threat)
# ORO Type
predOROAny <- readOROAnyPredictions(boundaries = "mean") %>%
  mutate(oro_branch = factor(oro_branch,
                             levels = c("mitigation","nature","societal"),
                             labels = c("Mitigation",
                                           "Natural resilience",
                                           "Societal adaptation"))) %>%
  filter(!(oro_any %in% c("Protection","Restoration"))) %>%
  mutate(oro_any = droplevels(oro_any)) %>%
  mutate(oro_any = recode_factor(
    oro_any, Renewables = "Renewable energy", Increase_efficiency = "Increase efficiency",
    CO2_removal_or_storage="CO2 removal or storage", 
    Human_assisted_evolution="Human-assisted evolution", Conservation="Conservation",
    Built_infrastructure_and_technology="Built infrastructure & technology",
    Socioinstitutional="Socio-institutional"
  ))

# Outcomes
# Mitigation
predMit <- readPredictions(boundaries = "mean", variable = "climate_mitigation") %>%
  mutate(outcome = recode_factor(climate_mitigation, 
                                 `0_relevance` = "Mitigation"),
         outcome_category = paste("Mitigation")) %>%
  mutate(outcome = as.character(outcome),
         outcome_category = as.character(outcome_category))%>%
  select(-c(climate_mitigation))
# Adaptation
predAdapt <- readPredictions(boundaries = "mean", variable = "adapt_to_threat_simplified2") %>%
  mutate(outcome = recode_factor(adapt_to_threat_simplified2,
                                 adapt_to_threat.Human = "Adapt: Humans", 
                                 adapt_to_threat.Natural = "Adapt: Nature"), 
         outcome_category = paste("Adaptation")) %>%
  mutate(outcome = as.character(outcome),
        outcome_category = as.character(outcome_category))%>%
  select(-c(adapt_to_threat_simplified2))
# Fuse together into one outcome variable
predOutcome <- rbind(predMit, predAdapt)
predOutcome <- predOutcome %>%
  select(analysis_id, outcome_category, outcome, mean)


# Data type -- one column for Primary and Secondary
predData <- readPredictions(boundaries = "mean", variable = "data") %>%
  filter(data == "type.Secondary") %>%
  mutate(Secondary = ifelse(0.5 <= mean, 1, 0)) %>%
  select(analysis_id, Secondary)


## FORMATTING & CALCULATIONS

# Bind all dataframes together with rows = analysis_id, columns : oro_type, outcome, Primary, Secondary
temp <- predOROAny %>% 
  filter(0.5 <= mean) %>% select(analysis_id, oro_any)%>%
  inner_join(predOutcome %>% filter(0.5 <= mean) %>% select(analysis_id, outcome)) %>%
  left_join(predData)

tempTab <- temp %>%
  group_by(oro_any, outcome) %>%
  summarise(n_articles = n_distinct(analysis_id)) %>%
  mutate(outcome = factor(as.character(outcome),
                          levels = c("Mitigation","Adapt: Humans", "Adapt: Nature")))

tempTabSecondary <- temp %>%
  filter(Secondary == 1) %>%
  group_by(oro_any, outcome) %>%
  summarise(n_secondary = n_distinct(analysis_id)) %>%
  mutate(outcome = factor(as.character(outcome),
                          levels = c("Mitigation","Adapt: Humans", "Adapt: Nature")))

  
tempTab <- tempTab %>%
  full_join(tempTabSecondary, by = c("oro_any","outcome")) 


## Plot
oroOutcomeData_ggp <- ggplot(tempTab, aes(x=oro_any, y=outcome))+
  geom_tile(aes(fill = log(n_articles)))+
  geom_text(aes(label = format(n_articles, big.mark=",")), vjust = -2, size=3)+
  geom_point(aes(y=outcome, size = n_secondary))+
  #scale_fill_distiller(palette = "Blues", direction = -1)+
  scale_size(breaks = seq(0,max(tempTab$n_secondary, na.rm=T), by=3))+
  scale_fill_viridis_c()+
  labs(x = "ORO type",y="Outcome",size = "N secondary\narticles", fill = "log(N articles)")+
  theme_bw()+
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)
  )



ggsave(
  file = here::here("figures/supplementary/oroType-Outcome-Secondary_heatmap.pdf"), 
  plot = oroOutcomeData_ggp,
  width = 6, height = 5, units="in"
)

```


## Three way heatmaps of oro type, ecosystem, outcome


```{r get phylopics for ecosystem type}
pics <- dir(here::here("figures/phylopics/"))

# get mangrove
if(!("mangrove.svg" %in% pics)){
  mangrove_uuid <- rphylopic::get_uuid(name = "Rhizophora mangle", n=5)
  mangrove_img <- rphylopic::pick_phylopic(name = "Rhizophora mangle", n = 1)
  mangrove_img <- rphylopic::get_phylopic("bacc6a59-80d2-461c-92d4-83cabc91cc39")
  rphylopic::save_phylopic(img=mangrove_img,
                path = here::here("figures/phylopics/mangrove.svg"))
}


# Get coral
if(!("coral.svg" %in% pics)){
  coral_img <- rphylopic::get_phylopic("32eeaa29-2e90-40b5-92fb-eb8d7fcab9ab")
  rphylopic::save_phylopic(img = coral_img,
              path = here::here("figures/phylopics/coral.svg"))
}


# Get macroalgae
if(!("macroalgae.svg" %in% pics)){
  macro_img <- rphylopic::get_phylopic("9acf11fa-89dd-4a56-b3da-8665c406c6f5")
  rphylopic::save_phylopic(img = macro_img,
              path = here::here("figures/phylopics/macroalgae.svg"))
}


# get seagrass -- for some reason I had to download this directly from the website
#seagrass_img <- rphylopic::get_phylopic("2534e10f-ea8e-436e-a8c8-13ac045eb867")
#rphylopic::save_phylopic(img = seagrass_img,
#              path = here::here("figures/phylopics/seagrass.svg"))

```


```{r ggplot heatmap ORO type ecosystem type and outcome}
library(heatmaply)
source(here::here("R/readOROAnyPredictions.R"))
source(here::here("R/readPredictions.R"))

## READ IN PREDICTIONS & Factor

# ORO Type
predOROAny <- readOROAnyPredictions(boundaries = "mean")
predOROAny$oro_branch <- factor(predOROAny$oro_branch,
                                levels = c("mitigation","nature","societal"),
                                labels = c("Mitigation",
                                           "Natural resilience",
                                           "Societal adaptation"))
predOROAny <- predOROAny %>% 
  filter(!(oro_any %in% c("Protection","Restoration"))) %>%
  mutate(oro_any = droplevels(oro_any))
  
predOROAny$oro_any <- recode_factor(predOROAny$oro_any, Renewables = "Renewable energy", 
                Increase_efficiency = "Increase efficiency",
    CO2_removal_or_storage="CO2 removal or storage", 
    Human_assisted_evolution="Human-assisted evolution",
    Conservation="Conservation",
    Built_infrastructure_and_technology="Built infrastructure & technology",
    Socioinstitutional="Socio-institutional"
)
summary(predOROAny)
levels(predOROAny$oro_any)

# Ecosystem type
predEcos <- readPredictions(boundaries = "mean", variable = "ecosystem_type")
predEcos <- predEcos %>%
  mutate(ecosystem_type = factor(as.character(ecosystem_type),
                                 levels = unique(as.character(ecosystem_type)),
                                 labels = gsub("_"," ", unique(as.character(ecosystem_type)))))

# Outcomes
predMit <- readPredictions(boundaries = "mean", variable = "climate_mitigation")
predAdapt <- readPredictions(boundaries = "mean", variable = "adapt_to_threat_simplified2")



## FORMATTING & CALCULATIONS

# Fuse mitigation and adaptation predictions into one "Outcome" Variable
predMit <- predMit %>%
  mutate(outcome = recode_factor(climate_mitigation, 
                                 `0_relevance` = "Mitigation"),
         outcome_category = paste("Mitigation")) %>%
  mutate(outcome = as.character(outcome),
         outcome_category = as.character(outcome_category))%>%
  select(-c(climate_mitigation))

predAdapt <- predAdapt %>%
  mutate(outcome = recode_factor(adapt_to_threat_simplified2,
                                 adapt_to_threat.Human = "Adapt: Humans", 
                                 adapt_to_threat.Natural = "Adapt: Nature"), #Both = "Adapt: Humans & nature"
         outcome_category = paste("Adaptation")) %>%
  mutate(outcome = as.character(outcome),
        outcome_category = as.character(outcome_category))%>%
  select(-c(adapt_to_threat_simplified2))

predOutcome <- rbind(predMit, predAdapt)
predOutcome <- predOutcome %>%
  select(analysis_id, outcome_category, outcome, mean)


  

summary(predOutcome)

# make a long-format dataframe of cateogory predictions for each article
# start with a dataframe of analysis_id, oro_branch, oro_any, ecosystem_type, outcome
# Filter out the "other" oro_type and ecosystem_type, and when there is no ecosystem type
# If there is no mitigation or adaptatoin outcome classified, classify as "Other"
temp <- predEcos %>% 
  filter(0.5 <= mean) %>% select(-c(mean))%>%
  filter(ecosystem_type != "Other") %>%
  mutate(ecosystem_type = droplevels(ecosystem_type)) %>%
  left_join(predOROAny %>% filter(0.5 <= mean) %>% select(-c(mean)), by = "analysis_id") %>%
  left_join(predOutcome%>% filter(0.5 <= mean) %>%select(-c(mean)), by = "analysis_id") %>%
  filter(!is.na(oro_any)) %>%
  #mutate(outcome = ifelse(is.na(outcome), "Other", outcome),
  #       outcome_category = ifelse(is.na(outcome_category), "Other", outcome_category)) %>%
  filter(!is.na(outcome)) %>%
  mutate(outcome_category = factor(outcome_category,
                                   levels = c("Mitigation","Adaptation"))) %>% 
  mutate(outcome = factor(as.character(outcome),
                          levels = c("Mitigation","Adapt: Humans", "Adapt: Nature"))) # "Adapt: Humans & nature"

summary(temp)

# Now grouping by the 3 variables: oro, ecosystem and outcome, tabulate the numbers of 
# co-occurences
tempTab <- temp %>%
  group_by(ecosystem_type, oro_any, outcome) %>%
  summarise(n_articles = n_distinct(analysis_id)) %>% 

outcomeTotals <- tempTab %>%
  group_by(outcome) %>%
  summarise(outcomeTotal = sum(n_articles, na.rm=T)) 

library(magick)
marsh_ras <- as.raster(image_fill(image_read(here::here("figures/phylopics/saltmarsh.jpg")),'none'))
mangrove_ras <- as.raster(image_fill(image_read_svg(here::here("figures/phylopics/mangrove.svg")),'none'))
coral_ras <- as.raster(image_fill(image_read_svg(here::here("figures/phylopics/coral.svg")),'none'))
macro_ras <- as.raster(image_fill(image_read_svg(here::here("figures/phylopics/macroalgae.svg")),'none'))
seagrass_ras <- as.raster(image_fill(image_read_svg(here::here("figures/phylopics/seagrass.svg")),'none'))


oro_eco_outcome_ggp <- tempTab %>%
  left_join(outcomeTotals)%>% 
  mutate(percentage = n_articles/outcomeTotal*100) %>%
  ggplot(aes(y=oro_any, x=ecosystem_type))+
  geom_tile(aes(fill = percentage))+
  facet_wrap(vars(outcome))+
  scale_fill_distiller(palette = "Blues", direction = 1)+
  scale_y_discrete(limits=rev)+
  geom_hline(yintercept = c(0.5,2.5,4.5), col="black", linewidth=0.5)+
  #add_phylopic(x="Mangrove", y=-10, img = mangrove_img, alpha = 1)+
  annotation_raster(marsh_ras, 0.5, 1.5, -2, -0)+
  annotation_raster(mangrove_ras, 1.5, 2.5, -2, -0)+
  annotation_raster(coral_ras, 2.5, 3.5, -2, -0)+
  annotation_raster(macro_ras, 3.5, 4.5, -2, -0)+
  annotation_raster(seagrass_ras, 4.5, 5.5, -2, -0)+
  coord_cartesian(ylim = c(-1.5, length(levels(tempTab$oro_any))), clip = 'off')+
  labs(
    x = "Ecosystem type", y = "ORO type", 
    fill = "% of\narticles",
    caption = paste(
      "total number of articles per panel =", paste(outcomeTotals$outcomeTotal, collapse=", "),
      "\nfor", paste(outcomeTotals$outcome, collapse=", "), "\noutcomes respectively"
    )
  )+
  theme_bw()+
  theme(
    #plot.margin = unit(c(0,0,0,0), "cm"),
    panel.grid = element_blank(),
    legend.position = "bottom",
    axis.text.x = element_text(angle=45, vjust=1, hjust=1)
    #axis.title.x = element_text(vjust = -8)
  )

oro_eco_outcome_ggp

ggsave(here::here("figures/main/oro-type_ecosystem_outcome_heatmap.pdf"), 
       plot = oro_eco_outcome_ggp,
       width = 7, height = 4.75, units = "in")

# Maybe make the values proportional?
# Add little infographics for ecosysstem type on the axis? 
# add hashing where humans & nature is not NA?
# Remove outcome == Other


```


## Sankey flow of blue carbon > Ecosystem type > mitigation outcome 

How many of the blue carbon articles actually look at mitigation outcomes?

```{r Sankey flow of blue carbon articles broken down by ecosystem type and mitigation outcome}
#remotes::install_github("davidsjoberg/ggsankey")
library(ggsankey)

# Blue carbon predictions >= 0.5
predBC <- readPredictions(boundaries = "mean", variable = "blue_carbon")
predBC <- predBC %>%
  filter(0.5 <= mean) %>%
  mutate(blue_carbon = paste("Blue carbon")) %>%
  select(-c(mean)) %>%
  select(analysis_id, blue_carbon)


# Ecosystem type
predEcos <- readPredictions(boundaries = "mean", variable = "ecosystem_type")
predEcos <- predEcos %>%
  filter(0.5 <= mean) %>%
  mutate(ecosystem_type = as.character(ecosystem_type)) %>%
  select(analysis_id, ecosystem_type)
  
ecosysLevels = unique(predEcos$ecosystem_type)


# Outcomes
predMit <- readPredictions(boundaries = "mean", variable = "climate_mitigation")
predMit <- predMit %>%
  filter(0.5 <= mean) %>%
  mutate(mitigation_outcome = paste("Mitigation")) %>%
  select(-c(mean)) %>%
  select(analysis_id, mitigation_outcome)


# I want 3 columns: blue carbon, ecosystem type (incl. other), Mitigation outcome, other
temp <- predBC %>%
  left_join(predEcos, by="analysis_id") %>%
  left_join(predMit, by = "analysis_id") %>%
  mutate(ecosystem_type = ifelse(is.na(ecosystem_type),"Other", ecosystem_type),
         mitigation_outcome = ifelse(is.na(mitigation_outcome),"Other", mitigation_outcome)) %>%
  mutate(ecosystem_type = factor(ecosystem_type,
                                 levels = c(ecosysLevels, "Other"),
                                 labels = c(gsub("_"," ", ecosysLevels), "Other")),
         mitigation_outcome = factor(mitigation_outcome, 
                                     levels = c("Mitigation", "Other")))

temp <- temp %>%
  make_long(blue_carbon, ecosystem_type, mitigation_outcome) 
  

tempTab <- temp %>%
  group_by(node) %>%
  tally()

temp <- merge(temp, tempTab, by = "node", all.x=TRUE)

## PLOT THE SANKEY DIAGRAM
blueCarbonSankey <- temp %>%
  ggplot(aes(x=x, next_x=next_x, node=node, next_node=next_node, 
             fill=factor(node), label = paste0(node, "\n n=", n))) +
  geom_sankey(flow.alpha=0.5, node.color = "black", show.legend = FALSE)+
  geom_sankey_label(size = 3, color = "black", fill= "transparent", hjust = -0.2)+
  #scale_fill_viridis_d()+
  scale_fill_manual(
    values = c(
      'Blue carbon' = "#1f78b4",
      'Seagrass' = '#b2df8a',
      'Salt marsh' = '#fb9a99',
      "Other" = "darkgrey",
      "Mangrove" = "#33a02c",
      "Macroalgae" = "#cab2d6",
      "Coral reef" = "#ff7f00",
      "Mitigation" = "#e31a1c"
    )
  )+
  labs(fill = 'Nodes')+
  theme_bw()+
  theme(
    legend.position = "none",
    panel.border = element_blank(),
    axis.text.y = element_blank(), 
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.ticks = element_blank(), 
    panel.grid = element_blank()
  )


ggsave(
  here::here("figures/main/blueCarbonEcosystemSankey.pdf"), plot=blueCarbonSankey,
  width = 7, height=4, units="in"
)
```

Maybe this can be done as a clustered barplot as well?


## Barchart of ORO types split by marine system (land, coastal, open), clustered by climate threat


```{r Barchart of ORO types split by marine system clustered by climate threat}
library(cowplot)

## Read in the infographic of the marine systems
marineSysImg <- magick::image_read(here::here("figures/inkscape/marineSystems.svg"))

## Read in data for plots (cluster by climate threat)
# ORO Type
predOROAny <- readOROAnyPredictions(boundaries = "mean")
predOROAny$oro_branch <- factor(predOROAny$oro_branch,
                                levels = c("mitigation","nature","societal"),
                                labels = c("Mitigation",
                                           "Natural resilience",
                                           "Societal adaptation"))
predOROAny <- predOROAny %>% 
  filter(!(oro_any %in% c("Protection","Restoration"))) %>%
  mutate(oro_any = droplevels(oro_any)) %>%
  mutate(oro_any = recode_factor(
    oro_any, Renewables = "Renewable energy", Increase_efficiency = "Increase efficiency",
    CO2_removal_or_storage="CO2 removal or storage", 
    Human_assisted_evolution="Human-assisted evolution", Conservation="Conservation",
    Built_infrastructure_and_technology="Built infrastructure & technology",
    Socioinstitutional="Socio-institutional"
  ))
# Marine system
predMarine <- readPredictions(boundaries = "mean", variable = "marine_system")
predMarine <- predMarine %>%
  mutate(marine_system = recode_factor(marine_system, 
                                       land = "Coastal land", 
                                       `coastal ocean` = "Coastal ocean",
                                       `open-ocean` = "Open-ocean"))
# Climate threat
predThreat <- readPredictions(boundaries = "mean", variable = "climate_threat")
predThreat <- predThreat %>%
  filter(climate_threat %in% c("Temperature","SLR","Extreme_weather")) %>%
  mutate(climate_threat = droplevels(climate_threat))
  


## DATA CALCULATIONS 

temp <- predMarine %>% filter(0.5 <= mean) %>% select(analysis_id, marine_system) %>%
  inner_join(predOROAny %>% filter(0.5 <= mean) %>% select(analysis_id, oro_any)) %>%
  left_join(predThreat %>% filter(0.5 <= mean) %>% select(analysis_id, climate_threat)) %>%
  mutate(climate_threat = factor(climate_threat, 
                                 levels = c("Temperature","SLR","Extreme_weather", NA), 
                                 labels = c("Temperature","Sea-level rise","Extreme weather", "Other"), 
                                 exclude = NULL))



## PLOTTING

marineSysOROThreat_ggp <- ggplot(temp, aes(x = oro_any, fill = climate_threat))+
  facet_wrap(vars(marine_system), ncol=1, scales = "free")+
  geom_bar(position = "stack")+
  labs(fill = "Climate threat", y = "Number of articles", x="ORO type")+ #
  scale_fill_brewer(palette = "Paired")+ # only one that's colourblind safe
  scale_x_discrete(limits = rev)+
  coord_flip()+
  theme_bw()+
  theme(
    #axis.text.x = element_text(angle = 45, hjust=1, vjust=1)
    legend.position = "right",
    axis.title.y = element_blank()
  )


# Plot of the svg infographic -- odd that the vecotor images of the icons don't show up
marineSysImg_ggp <- ggdraw()+draw_image(marineSysImg, scale = 1)



## Save file
pdf(file = here::here("figures/main/marineSystem-ORO-climateThreat_barplot.pdf"),
    width = 10, height = 5)
plot_grid(marineSysImg_ggp, marineSysOROThreat_ggp, rel_widths = c(1,1.5))
while (!is.null(dev.list())) dev.off()

```


# Geoparsing results

Sankey Diagram of First Author Affiliation compared to where research is conducted by continent/region

Maps of # articles by ORO type? ie. one panel with one map/ORO type 



