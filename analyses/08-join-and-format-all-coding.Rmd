---
title: "08-join-and-format-all-coding"
author: "Devi Veytia"
date: "2023-04-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load libraries}
library(dplyr)
library(dbplyr)
library(R.utils)
library(RSQLite)
```



# Read in all coding results and format

## Initial sets

** still need to run once the code checking is finalized

```{r format initial sets into binary columns for predictions in distilBERT}
## READ IN FILES

# files of coding results
codingDir <- here::here("data","derived-data","coding","manual-coding","sets")
codingFiles <- dir(codingDir)
codingFiles <- codingFiles[grepl(".csv", codingFiles)] # only include csv files

for(f in 1:length(codingFiles)){
  
  # determine whether to also produce a string of variable names 
  # only do this for the first loop
  if(f==1){
    returnVariableString = TRUE
  }else{
    returnVariableString = FALSE
  }
  
  # read in codebook and format
  df <- formatCoding2distilBert(
    codebookFp=file.path(codingDir, codingFiles[f]),
    skipLines=3,returnVariableString = returnVariableString,
    exclusions = TRUE)
  
  
  # for now, just condense everything so it is 1 row x publication
  # columns 1:5 and last column are ID columns, and 6 onwards have data
  # condense data columns
  condensedDat <- apply(df$data[,7:ncol(df$data)-1], 2, FUN=function(x) tapply(X=x, INDEX=df$data$sysrev_id, FUN=sum, na.rm=T))
  condensedDat[condensedDat>1] <- 1 # reduce all sums to just p/a
  condensedDat <- as.data.frame(condensedDat, row.names = rownames(condensedDat))
  condensedDat <- tibble::rownames_to_column(condensedDat, "sysrev_id")
  
  # join back with corresponding id columns
  # I don't know why, but even with left_join duplciates in y cause duplication in x so need to rm duplicates first
  idCols <- df$data[,c("sysrev_id","title","year","coder_1","coder_2")]
  idCols <- idCols[!duplicated(idCols),]
  condensedDat <- condensedDat %>% left_join(idCols, by="sysrev_id")
  # get column names in right order
  colOrder <- colnames(df$data)
  colOrder <- colOrder[-which(colOrder %in% c("notes"))]
  condensedDat <- condensedDat[,colOrder]
  df$data <- condensedDat; rm(condensedDat)

  
  # save
  if(f==1){
    variables <- df$variables
    responseDf <- df$data
  }else{
    responseDf <- rbind(responseDf, df$data)
  }
  
}

#View(responseDf)

```


Make sure that these column names are included: "impact_economy.Tourism__Recreation" "impact_economy.Informal"           
[7] "impact_economy.Livelihood"          "impact_economy.Other"

And not "impact_economy.Tourism" "impact_economy.other" --> then there is an error in the impact_economy column, row 1 of the .csv file
```{r check for consistency in column names}
colnames(responseDf)
```


```{r save screening decisions seperately}
write.csv(responseDf[,1:6], 
          here::here("data","derived-data","screening","screened-records","coding-screening_initialSets.csv"),
          row.names = FALSE)

responseDf <- responseDf[,which(colnames(responseDf) != "include_code")]
```



```{r read in combined answers from set-0 and merge in with responses from other sets}
set0Responses <- readr::read_csv(
  here::here("data","derived-data","coding","manual-coding","set-0_check","codebook_combined-formatted_set-0.csv"), 
  show_col_types = FALSE
  )

responseDf <- rbind(set0Responses, responseDf)
```

```{r use the lookup table to join with analysis_id duplicate_id abstract and keywords}
require(dbplyr)
require(R.utils)
require(RSQLite)

all_db <- RSQLite::dbConnect(RSQLite::SQLite(),
                      here::here("data","raw-data","sql-databases", "all_tables_v1.sqlite"), 
                                 create=FALSE)

src_dbi(all_db) # look at all the tables in the database

# unique reference metadata
dedups <- tbl(all_db, "uniquerefs")
dedup_sub <- dedups %>% 
  select(analysis_id, duplicate_id, title, year, abstract, keywords)

# lookup table of the sysrev_id to duplicate_id
sysrev_id <- tbl(all_db, "sysrevid_2_analysisid_lookup")
sysrev_id <- sysrev_id %>% select(duplicate_id, sysrev_id)

# join to get the relevant ids
relevantData <- sysrev_id %>%
  left_join(dedup_sub, by = "duplicate_id") %>%
  collect()

# disconnect
RSQLite::dbDisconnect(all_db)

dim(responseDf)

# merge metadata in by sysrev_id and order columns
responseDf <- responseDf %>%
  select(-c(title,year)) %>%
  left_join(relevantData, by = "sysrev_id")

idCols <- c("sysrev_id","analysis_id", "duplicate_id","title","abstract","keywords","year","coder_1","coder_2")
responseDf <- responseDf[,c(idCols, colnames(responseDf)[which(!(colnames(responseDf) %in% idCols))])]

# check there are now NAs for analysis_id or duplicate_id
sum(is.na(responseDf$analysis_id))
sum(is.na(responseDf$duplicate_id))
```

```{r add responses as a table to the sqlite database}
require(dbplyr)
require(R.utils)
require(RSQLite)

all_db <- RSQLite::dbConnect(RSQLite::SQLite(),
                      here::here("data","raw-data","sql-databases", "all_tables_v1.sqlite"), 
                                 create=FALSE)

RSQLite::dbWriteTable(all_db, "initial_coding", responseDf, overwrite=TRUE)

src_dbi(all_db)

RSQLite::dbDisconnect(all_db)

```


## Supplementary sets

```{r format supplementary sets}

## READ IN FILES

# files of coding results
codingDir <- here::here("data","derived-data","coding","manual-coding","supplementary-sets")
codingFiles <- dir(codingDir)
codingFiles <- codingFiles[grepl(".csv", codingFiles)] # only include csv files

for(f in 1:length(codingFiles)){
  
  # determine whether to also produce a string of variable names 
  # only do this for the first loop
  if(f==1){
    returnVariableString = TRUE
  }else{
    returnVariableString = FALSE
  }
  
  # read in codebook and format
  df <- formatCoding2distilBert(
    codebookFp=file.path(codingDir, codingFiles[f]),
    skipLines=3,returnVariableString = returnVariableString,
    exclusions = FALSE)
  
  # change column name because actually these weren't screened in sysrev so they don't have a sysrev_id
  colnames(df$data)[1] <- "duplicate_id"
  
  
  # for now, just condense everything so it is 1 row x publication
  # columns 1:5 and last column are ID columns, and 6 onwards have data
  # condense data columns
  condensedDat <- apply(df$data[,7:ncol(df$data)-1], 2, FUN=function(x) tapply(X=x, INDEX=df$data$duplicate_id, FUN=sum, na.rm=T))
  condensedDat[condensedDat>1] <- 1 # reduce all sums to just p/a
  condensedDat <- as.data.frame(condensedDat, row.names = rownames(condensedDat))
  condensedDat <- tibble::rownames_to_column(condensedDat, "duplicate_id")
  
  # join back with corresponding id columns
  # I don't know why, but even with left_join duplciates in y cause duplication in x so need to rm duplicates first
  idCols <- df$data[,c("duplicate_id","title","year","coder_1","coder_2")]
  idCols <- idCols[!duplicated(idCols),]
  condensedDat <- condensedDat %>% left_join(idCols, by="duplicate_id")
  # get column names in right order
  colOrder <- colnames(df$data)
  colOrder <- colOrder[-which(colOrder %in% c("notes"))]
  condensedDat <- condensedDat[,colOrder]
  df$data <- condensedDat; rm(condensedDat)


  
  
  # save
  if(f==1){
    variables <- df$variables
    responseDf <- df$data
  }else{
    responseDf <- rbind(responseDf, df$data)
  }
  
}

#View(responseDf)



```

```{r check that duplicate id is correct}
# text used for supplemental search
my_text <- readRDS(here::here("data","derived-data","coding","keyword-matches-supplemental-coding","screeningText.rds"))


# find title matches
matches <- rep(NA, nrow(responseDf))

for(i in 1:length(matches)){
  matches[i] <- stringdist::amatch(tolower(responseDf$title[i]), tolower(my_text$title), method = "osa", maxDist = 5, nomatch = NA)
}


# join with matches
responseDf2 <- cbind(
  my_text[matches,c("analysis_id","duplicate_id","title","abstract","keywords","year")],
  responseDf[,-c(1:3)]
)


```


```{r add supplementary responses as a table to the sqlite database}
require(dbplyr)
require(R.utils)
require(RSQLite)

all_db <- RSQLite::dbConnect(RSQLite::SQLite(),
                      here::here("data","raw-data","sql-databases", "all_tables_v1.sqlite"), 
                                 create=FALSE)

#RSQLite::dbWriteTable(all_db, "supplementary_coding", responseDf2, overwrite=TRUE)



RSQLite::dbDisconnect(all_db)

```


# Merge all together and simplify columns


```{r merge with abstract and id metadata}

require(dbplyr)

all_db <- dbConnect(RSQLite::SQLite(),
                      here::here("data","raw-data","sql-databases", "all_tables_v1.sqlite"), 
                                 create=FALSE)

src_dbi(all_db) # look at all the tables in the database

# coding results from initial round
initialCoding <- tbl(all_db, "initial_coding")
initialCoding <- initialCoding %>% collect()

# coding results from supplemental round
supplementaryCoding <- tbl(all_db, "supplementary_coding")
supplementaryCoding <- supplementaryCoding %>% collect()
supplementaryCoding$sysrev_id <- rep(NA, nrow(supplementaryCoding)) # add a black sysrev_id

# check what columns they have in common and if any important ones are missing
cols <- intersect(colnames(initialCoding), colnames(supplementaryCoding))
colnames(initialCoding)[which(!(colnames(initialCoding) %in% colnames(supplementaryCoding)))]
colnames(supplementaryCoding)[which(!(colnames(supplementaryCoding) %in% colnames(initialCoding)))]

  
## Disconnect databases
dbDisconnect(all_db)


```


```{r simplify coding variables}
idCols <- c("sysrev_id","analysis_id","duplicate_id","title","abstract","keywords","year","coder_1","coder_2")

source(here::here("R","simplifyCodebook.R"))

codebookCombined <- simplifyCodebook(supplementaryCoding, idCols)


# write for Vicky & save
write.table(
  codebookCombined,
  file = here::here("data","derived-data","coding", "all-coding-format-distilBERT.txt"),
  row.names=F, col.names=TRUE, sep='\t', quote=FALSE
)

save(codebookCombined, here::here("data","derived-data","coding", "all-coding-format-distilBERT.RData"))

```



# Compare these with all the articles that were screened to come up with updated screening decisions data


```{r compile final screening decisions from both initial and supplementary coding rounds}

## From initial round 
codingScreen0 <- read.csv(
  here::here("data","derived-data","screening","screened-records","coding-screening_set-0.csv"))
codingScreen <- read.csv(
  here::here("data","derived-data","screening","screened-records","coding-screening_initialSets.csv"))
codingScreen <- rbind(codingScreen, codingScreen0)
rm(codingScreen0)

# rename columns
codingScreen <- codingScreen %>%
  rename(reviewer = coder_1, reviewer_2 = coder_2, include_screen = include_code) %>%
  select(sysrev_id, reviewer, reviewer_2, include_screen)

# use the lookup table to join sysrev_id to analysis_id and duplicate_id
all_db <- RSQLite::dbConnect(RSQLite::SQLite(),
                      here::here("data","raw-data","sql-databases", "all_tables_v1.sqlite"),
                                 create=FALSE)

sysrevIDLookup <- tbl(all_db, "sysrevid_2_analysisid_lookup")

dedups <- tbl(all_db,"uniquerefs")

codingScreen <- codingScreen %>%
  left_join(sysrevIDLookup, by="sysrev_id", copy=TRUE) %>%
  left_join(dedups %>% select(duplicate_id, abstract, keywords), by = "duplicate_id", copy=TRUE)

if("title.x" %in% colnames(codingScreen)){
  codingScreen$title.x <- NULL
  codingScreen <- codingScreen %>% rename(title = title.y)
}

RSQLite::dbDisconnect(all_db)

# need to get sample_screen from initial screening results
load(here::here("data","derived-data","screening","screened-records","screen_results_merged.RData"))

codingScreen <- codingScreen %>%
  left_join(screen_results_merged %>% select(sysrev_id, sample_screen))

# format columns
codingScreen$include_screen <- codingScreen$include_screen == 1
codingScreen$sample_screen <- as.character(codingScreen$sample_screen)







## From the supplementary round
supplementalScreenDir <- here::here("data","derived-data","coding","keyword-matches-supplemental-coding","screening")
supplementalScreenFiles <- dir(supplementalScreenDir)

for(f in 1:length(supplementalScreenFiles)){
  temp <- read.csv(file.path(supplementalScreenDir, supplementalScreenFiles[f]))
  temp <- subset(temp, !is.na("screened_abstracts"))
  if(f==1){
    supplementalScreen <- temp
  }else{
    supplementalScreen <- rbind(supplementalScreen, temp)
  }
}
# remove skipped articles
supplementalScreen <- subset(supplementalScreen, !is.na(screened_abstracts))

# add columns to be consistent with above
supplementalScreen$reviewer <- rep("Devi", nrow(supplementalScreen))
supplementalScreen$reviewer_2 <- rep(NA, nrow(supplementalScreen))
supplementalScreen$include_screen <- supplementalScreen$screened_abstracts == "selected"
supplementalScreen$sample_screen <- "supplemental coding"


# join with metadata id information
# text used for supplemental search
my_text <- readRDS(here::here("data","derived-data","coding","keyword-matches-supplemental-coding","screeningText.rds"))

# find title matches
matches <- rep(NA, nrow(supplementalScreen))

for(i in 1:length(matches)){
  matches[i] <- stringdist::amatch(tolower(supplementalScreen$title[i]), tolower(my_text$title), method = "osa", maxDist = 5, nomatch = NA)
}

sum(is.na(matches))

# join with matches
supplementalScreen2 <- cbind(
  my_text[matches,c("analysis_id","duplicate_id","title","abstract","keywords","year")],
  supplementalScreen[,c("reviewer","include_screen","sample_screen")]
)

# make empty column for reviewer 2 
supplementalScreen2$reviewer_2 <- rep(NA, nrow(supplementalScreen2))



## Join both data frames together
cols <- intersect(colnames(supplementalScreen2), colnames(codingScreen))
cols <- cols[c(1,2,8,3,4,5,6,7,10,9)] # re-order so its more sensible
allCodingJoin <- rbind(
  supplementalScreen2[,cols], codingScreen[,cols]
)

# format
allCodingJoin$reviewer <- as.factor(allCodingJoin$reviewer)
allCodingJoin$reviewer_2 <- as.factor(allCodingJoin$reviewer_2)
allCodingJoin$sample_screen <- as.factor(allCodingJoin$sample_screen)
summary(allCodingJoin)



## Save
write.table(
  allCodingJoin,
  file = here::here("data","derived-data","screening","screened-records","all-screen-results_afterSupplementalCoding.txt"),
  row.names=F, col.names=TRUE, sep='\t', quote=FALSE
)

save(allCodingJoin, here::here("data","derived-data","screening","screened-records",
                                  "all-screen-results_afterSupplementalCoding.RData"))
```






# Junk

```{r supplementary coding}
all_db <- RSQLite::dbConnect(RSQLite::SQLite(),
                      here::here("data","raw-data","sql-databases", "all_tables_v1.sqlite"), 
                                 create=FALSE)

src_dbi(all_db)

# coding results
supCoding <- tbl(all_db, "supplementary_coding")
supCoding <- supCoding %>%
  select(-c(title, year, coder_1, coder_2))

# unique reference metadata
dedups <- tbl(all_db, "uniquerefs")
dedups <- dedups %>% 
  select(analysis_id, title, abstract, keywords)

# join together
supCodingDf <- left_join(supCoding, dedups, by = "analysis_id") %>% collect() 

# check for NAs
sum(is.na(supCodingDf$abstract))
View(supCodingDf[is.na(supCodingDf$abstract),])

idCols <- c("duplicate_id","title","abstract","keywords")
supCodingDf <- supCodingDf[,c(idCols, colnames(supCodingDf)[which(!(colnames(supCodingDf) %in% idCols))])]
summary(supCodingDf[,idCols])


# but there are some which have not abstract matches
RSQLite::dbDisconnect(all_db)
```




