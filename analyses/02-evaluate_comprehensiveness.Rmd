---
title: "02-evaluate_comprehensiveness"
author: "Devi Veytia"
date: "2023-01-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r load libraries}
library(dplyr)
library(stringi)
library(stringr)
```

```{r set up inputs}

## file locations for search string
search_string_dir <- here::here("data","derived-data","search-string")
search_string_fp <- file.path(search_string_dir,"search-string-blocks.xlsx")


```




Using the test list, the search strings and the search results, I want to evaluate the comprehensiveness of the search string.


# Format the search string

Using the search string components (formula, keywords and substrings) stored in the file search-string.xlsx, build the full search string and format for Scopus

## For WOS


```{r search string build for wos, echo=FALSE}

## Read in files
searchStringDf <- readxl::read_excel(path = search_string_fp, sheet = "sub-strings", trim_ws = TRUE)
colnames(searchStringDf) <- gsub("\\s",".",colnames(searchStringDf))

keywords <- readxl::read_excel(path = search_string_fp, sheet = "commonly-used-keywords", trim_ws = TRUE)
colnames(keywords) <- gsub("\\s",".",colnames(keywords))

searchFormula <- readxl::read_excel(path = search_string_fp, sheet="search-formula", trim_ws = TRUE)


  
## Put in commonly-used keywords into string
searchStringDf$Search.Terms <- stri_replace_all_fixed(
    searchStringDf$Search.Terms, keywords$Key.Term, keywords$Search.Terms, vectorise_all = FALSE
    )



# # test each block to see if it works
# cat(paste(searchStringDf[13,3]))



## extract terms based on search formula
# remove operators
rm_boolean <- function(x){
  y <- str_remove_all(str_remove_all(str_remove_all(str_remove_all(x,"AND"), "OR"), "NOT"), "NEAR")
  y <- gsub("[0-9]", "", y)
  y <- gsub("/","",y)
  return(y)
}

searchTerms <- apply(searchFormula, 2, rm_boolean)

searchTerms <- unique(unlist(str_split(searchTerms, boundary("word"))))
searchTermsDf <- matrix(nrow=length(searchTerms), ncol=2)
searchTermsDf[,1] <- searchTerms

for(i in 1:length(searchTerms)){
  searchTermsDf[i,2] <- paste0("(",paste0(searchStringDf$Search.Terms[which(searchStringDf$Group == searchTerms[i])], collapse="OR"),")")
}

# # check chunks of search terms
# cat(searchTermsDf[8,2])

## Use search formulas to combine terms 
wos_equation <- data.frame(Search.Formula = searchFormula[,1])
wos_equation$Search.String <- NA

for(i in 1:nrow(wos_equation)){
  wos_equation$Search.String[i] <- stri_replace_all_fixed(
    wos_equation$Search.Formula[i], searchTermsDf[,1], searchTermsDf[,2], vectorise_all = FALSE
    )
}


# # check 
# cat(wos_equation[1,2])

cat(wos_equation[8,2])
  

```

```{r write search string to text file, eval=FALSE}
# # write as .txt file
# sink(file.path(search_string_dir, "wos-equation.txt"))
# for(i in 1:nrow(wos_equation)){cat(wos_equation[i,1],"\n", wos_equation[i,2],"\n","\n")}
# sink()
  
```

Write recursively as well because WOS cannot display > 100,000 articles at a time. Seperate by date range

```{r write WOS search equation partitioned by year}
year_brackets <- c("1946-2009","2010-2015", "2016-2019","2020-2023")
# 
# sink(file.path(search_string_dir,"wos-equation_partitionedByYear.txt"))
# for(i in 1:length(year_brackets)){
#   cat("TS = (", wos_equation$Search.String[7], ") AND  LA=(English) AND (PY = ",year_brackets[i],")", "\n","\n")
# }
# sink()
```


## For Scopus


```{r search string format for scopus, echo=FALSE}

## Set up

# get a list of all the sheets to iterate over
sheets <- readxl::excel_sheets(path = search_string_fp)

# set up a dataframe to store the string results
string_blocks_scopus <- data.frame(Block = sheets)
string_blocks_scopus$String <- NA


## Loop through the sheets and read in and format the string

for(s in 1:length(sheets)){
  
  ## read in the search string for each block located within each sheet
  # read in file
  temp <- readxl::read_excel(path = search_string_fp, sheet = sheets[s], trim_ws = TRUE, skip = 2)
  temp <- temp %>% select(-c(Date, `Search #`, Block, `Test list results`, `Total search results`, Comments))
  
  # fill in empty columns with boolean operator
  for(c in 1:ncol(temp)){
    if(sum(is.na(temp[,c])) == nrow(temp)){
      temp[,c] <- str_remove_all(colnames(temp)[c], "[^[:alpha:]]") # have to clean out unique suffix of column name e.g. "...5"
    }
  }
  
  # to handle "" fill with the value from the previous row
  for(i in 1:dim(temp)[1]){
    for(j in 1:dim(temp)[2]){
      if(is.na(temp[i,j])){next}
      if(temp[i,j] == "\"\""){
        temp[i,j] <- temp[i-1,j]
      }else{
        next
      }
    }
  }
  
  # the last row is where the final string is stored
  string <- temp[nrow(temp),]
  
  # clean out an NA and preceeding boolean operator if it is present
  if(sum(is.na(string))>0){
    naInd <- which(is.na(string))
    rmOper <- naInd+1
    string[-c(naInd, rmOper)]
  }
  
  
  ## Format the string for Scopus
  
  # replace NEAR/x operators
  string <- unlist(gsub("NEAR","W",string))
  
  # replace "NOT" with "AND NOT"
  string <- unlist(gsub("NOT", "AND NOT",string))
  
  # Replace with the scopus field codes
  string <- unlist(gsub("TS = ", "TITLE-ABS-KEY",string))
  string <- unlist(gsub("LA=", "LANGUAGE",string))
  
  # combine seperate elements together into one string
  string <- paste0(string, collapse =" ")
  
  # store
  string_blocks_scopus$String[s] <- string
  
}


```


```{r write search equation for scopus to txt file}

# # add in field codes and write to text file
# 
# sink(file.path(search_string_dir,"scopus-equation-blocks.txt"))
# for(s in 1:length(sheets)){
#   cat(string_blocks_scopus$Block[s],"\n",string_blocks_scopus$String[s],"\n","\n")
# }
# sink()
```

For Scopus it might make the most sense to download records by source title, becaues there are only 4 records that exceed 2,000 references

Numbers of total results from scopus per block (Jan 30 2023):
General: 221
Renewables: 85,425
Mitigation: 55,631
Nature: 1442
Societal: 488

total = 142,907 


# Evaluate comprehensiveness


Using the test list, evaluate the comprehensiveness of the search in WOS. Do this by entering the search string in the topic field, and using an "AND" boolean operator, entering DO = the dois of the test list articles. If the number of returns = the number of test list articles I have full retrieval. To see which articles are not retrieved, search the DO = test list article dois, NOT TS = my WOS search string.


DETAILS OF SEARCH

Search on Jan 18 2023

Total articles retrieved: 320,936
test list articles = all 97 that are indexed in WOS were retrieved


```{r set up dataframes to store results}
# set up dataframe for results
searchFormulaEval_summary <- data.frame(
  Search_no = 1:(length(searchFormula$Search.Formula)+1),
  Search.Formula= c(searchFormula$Search.Formula, "Add (pollution OR pollutant$) to NOT terms"))
searchFormulaEval_summary$N_total_results <- NA
searchFormulaEval_summary$N_test_list <- NA

# get number of test list articles
test_list <- readxl::read_xlsx(file.path(scopeSearchDir, "derived_data", "screen_test_list","test-list_2023-01-19.xlsx"))
n_test_list <- nrow(test_list)

## Fill in results
searchFormulaEval_summary[1,2:3] <- c(42555,18)
searchFormulaEval_summary[2,2:3] <- c(498888, 89)
searchFormulaEval_summary[3,2:3] <- c(13869,29)
searchFormulaEval_summary[4,2:3] <- c(152368, 50)
searchFormulaEval_summary[5,2:3] <- c(163312, 72)
searchFormulaEval_summary[6,2:3] <- c(10138, 29)
searchFormulaEval_summary[7,2:3] <- c(292256, 97)
searchFormulaEval_summary[8,2:3] <- c(277012,95)

# add column for proportion of test list articles
searchFormulaEval_summary$N_percent_test_list <- searchFormulaEval_summary$N_test_list/n_test_list*100

View(searchFormulaEval_summary)

# # write to excel file for putting in paper
# writexl::write_xlsx(searchFormulaEval_summary, 
#                     here::here("outputs","scopingSearchSummary.xlsx"))

```


Therefore the final search string follows the formula in row 7.

Note when I refine for english, it goes from 292256 - 287,965




## Combine test list items returned from each block


```{r}
returnTestListDir <- here::here("data","raw-data","WOS_downloads","test-list-returns-by-block")
returnTestListFiles <- dir(returnTestListDir)

# read in and de-duplicate test list returns
temp <- rbibtools::read_bib(here::here(returnTestListDir))
temp$unique_id <- revtools::find_duplicates(temp)
temp <- temp[!duplicated(temp$unique_id),]
nrow(temp)

# compare to test list
# read in test list
test_list <- readxl::read_excel(here::here("data", "derived-data", "screen_test_list", "test-list_2023-01-19.xlsx"))

# identify if any test list items are not included
ind <- which(!(test_list$doi %in% temp$doi))
if(length(ind)>0){
  View(test_list[ind,])
}else{
  print("all test list articles retreived")
}



```























